---
# Header
title: "10.ì•™ì¼€íŠ¸ ë¶„ì„ì„ ìœ„í•œ ìì—°ì–´ ì²˜ë¦¬ í…Œí¬ë‹‰ 10"
excerpt: "ì•™ì¼€íŠ¸ ë¶„ì„ì„ ìœ„í•œ ìì—°ì–´ ì²˜ë¦¬ í…Œí¬ë‹‰ 10"
name: J
writer: J
categories: [ë°ë¹„&ì¶”ì²œì‹œìŠ¤í…œ, íŒŒì´ì¬ ë°ì´í„°ë¶„ì„ ì‹¤ë¬´ í…Œí¬ë‹‰ 100] # [ë©”ì¸ ì¹´í…Œê³ ë¦¬, ì„œë¸Œ ì¹´í…Œê³ ë¦¬]
tags:
  - [Khuda, ML, data]

toc: true
toc_sticky: true

date: 2024-11-01
last_modified_at: 2024-11-01

# --- ì•„ë˜ ë¶€í„° content
---

ğŸ”–ì „ì œì¡°ê±´

- survey.csv: ì•™ì¼€íŠ¸ ê²°ê³¼
    - ìº í˜ì¸ ê¸°ê°„(2019ë…„ 1ì›” ~ 4ì›”)ì˜ 4ê°œì›” ë™ì•ˆ ëª¨ì€ ê³ ê°ë§Œì¡±ë„ ì„¤ë¬¸ì¡°ì‚¬ ë°ì´í„°ê°€ ë°ì´í„°ë² ì´ìŠ¤ì— ê¸°ë¡ë¼ ìˆìŒ
    - ì„¤ë¬¸ì¡°ì‚¬ë¥¼ í•œ ë‚ ì§œ, ì˜ê²¬, ë§Œì¡±ë„(5ë‹¨ í‰ê°€)ì˜ ê²°ê³¼ê°€ ë“¤ì–´ ìˆìŒ.

# 091.ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì„œ íŒŒì•…í•´ ë³´ì

### ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°

```py
import pandas as pd
survey = pd.read_csv("survey.csv")
print(len(survey))
survey.head()
```
![alt text](/assets/img_20241102/image-36.png)

### ê²°ì¸¡ì¹˜ í™•ì¸

```py
survey.isna().sum()
```
![alt text](/assets/img_20241102/image-37.png)

### ê²°ì¸¡ì¹˜ ì œê±°

```py
survey = survey.dropna()
survey.isna().sum()
```
![alt text](/assets/img_20241102/image-38.png)

# 092.ë¶ˆí•„ìš”í•œ ë¬¸ìë¥¼ ì œê±°í•˜ì

- íŠ¹ì • ë¬¸ì ì œê±° / ì •ê·œ í‘œí˜„ì‹ í™œìš©

### íŠ¹ìˆ˜ë¬¸ì ì œê±°

```py
survey["comment"] = survey["comment"].str.replace("AA", "")
survey.head()
```
![alt text](/assets/img_20241102/image-39.png)

### ì •ê·œ í‘œí˜„ìœ¼ë¡œ ì œê±°

- ì •ê·œ í‘œí˜„ì‹
    - ë¬¸ìë¥¼ ì¼ì •í•œ ê·œì¹™ìœ¼ë¡œ ì œê±°í•  ë•Œ ì´ìš©
    - ì •ê·œ í‘œí˜„ì‹ì€ ë¬¸ì ë“±ì˜ íŒ¨í„´ì„ í‘œí˜„í•  ìˆ˜ ìˆìŒ
    - ê´„í˜¸ì˜ íŒ¨í„´ì„ ê²€ìƒ‰í•´ì„œ ì¹˜í™˜í•  ìˆ˜ ìˆìŒ

```py
survey["comment"] = survey["comment"].str.replace("\(.+?\)", "")
# regex=Trueë¡œ ì„¤ì •í•˜ë©´ str.replace()ì—ì„œ ì²« ë²ˆì§¸ ì¸ìˆ˜ë¥¼ ì •ê·œ í‘œí˜„ì‹ìœ¼ë¡œ ì¸ì‹
# '\(' ì™€ '\)'ëŠ” ()ë¥¼ ì˜ë¯¸
# .+?ëŠ” 1ë¬¸ì ì´ìƒì´ë¼ëŠ” ì˜ë¯¸
survey.head()
```
![alt text](/assets/img_20241102/image-40.png)

# 093.ë¬¸ì ìˆ˜ë¥¼ ì„¸ì–´ íˆìŠ¤í† ê·¸ë¨ìœ¼ë¡œ í‘œì‹œí•´ ë³´ì

### length ì¹¼ëŸ¼ ì¶”ê°€

```py
survey["length"] = survey["comment"].str.len()
survey.head()
```
![alt text](/assets/img_20241102/image-41.png)

### ì˜ê²¬ ê¸¸ì´ íˆìŠ¤í† ê·¸ë¨

```py
import matplotlib.pyplot as plt
%matplotlib inline
plt.hist(survey["length"])
# ê³µë°± í¬í•¨
```
![alt text](/assets/img_20241102/image-42.png)

# 094.í˜•íƒœì†Œ ë¶„ì„ìœ¼ë¡œ ë¬¸ì¥ì„ ë¶„ì„í•´ ë³´ì

- í˜•íƒœì†Œ ë¶„ì„: ë¬¸ì¥ì„ ë‹¨ì–´ë¡œ ë¶„í• í•˜ëŠ” ê¸°ìˆ (ex.konlpy)

### í˜•íƒœì†Œ ë¶„ì„

```py
from konlpy.tag import Twitter
twt = Twitter()
text = "í˜•íƒœì†Œë¶„ì„ìœ¼ë¡œ ë¬¸ì¥ì„ ë¶„í•´í•´ë³´ì"
tagging = twt.pos(text)
tagging
```
![alt text](/assets/img_20241102/image-43.png)

### í˜•íƒœì†Œ ë¶„ì„ì„ ì´ìš©í•œ ë‹¨ì–´ ì¶”ì¶œ

```py
words = twt.pos(text)
words_arr = []
for i in words:
    if i == 'EOS': continue
    # 'EOS'ëŠ” ë¶„ì„ ê²°ê³¼ì˜ ëì„ ì˜ë¯¸í•˜ë¯€ë¡œ, ì´ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.
    word_tmp = i[0]
    words_arr.append(word_tmp)
words_arr
```
![alt text](/assets/img_20241102/image-44.png)

# 095.í˜•íƒœì†Œ ë¶„ì„ìœ¼ë¡œ ë¬¸ì¥ì—ì„œ 'ë™ì‚¬', 'ëª…ì‚¬'ë¥¼ ì¶”ì¶œí•´ ë³´ì

```PY
text = "í˜•íƒœì†Œë¶„ì„ìœ¼ë¡œ ë¬¸ì¥ì„ ë¶„í•´í•´ë³´ì"
words_arr = []
parts = ["Noun", "Verb"]
words = twt.pos(text)
words_arr = []
for i in words:
    if i == 'EOS' or i == '': continue
    word_tmp = i[0]
    part = i[1]
    if not (part in parts):continue
    words_arr.append(word_tmp)
words_arr
```
![alt text](/assets/img_20241102/image-45.png)

# 096.í˜•íƒœì†Œ ë¶„ì„ìœ¼ë¡œ ìì£¼ ë‚˜ì˜¤ëŠ” ëª…ì‚¬ë¥¼ í™•ì¸í•´ ë³´ì

### survey ë°ì´í„°ì—ì„œ ëª…ì‚¬ ì¶”ì¶œ

```py
all_words = []
parts = ["Noun"]
for n in range(len(survey)):
    text = survey["comment"].iloc[n]
    words = twt.pos(text)
    words_arr = []
    for i in words:
        if i == "EOS" or i == "": continue
        word_tmp = i[0]
        part = i[1]
        if not (part in parts):continue
        words_arr.append(word_tmp)
    all_words.extend(words_arr)
print(all_words)
```
![alt text](/assets/img_20241102/image-46.png)

### survey ë°ì´í„° ë§ì´ ë‚˜ì˜¤ëŠ” ë‹¨ì–´

```py
all_words_df = pd.DataFrame({"words":all_words, "count":len(all_words)*[1]})
all_words_df = all_words_df.groupby("words").sum()
all_words_df.sort_values("count",ascending=False).head()
```
![alt text](/assets/img_20241102/image-47.png)

# 097.ê´€ê³„ì—†ëŠ” ë‹¨ì–´ë¥¼ ì œê±°í•´ ë³´ì

### ì œì™¸ í‚¤ì›Œë“œ ì œê±°

```py
stop_words = ["ë”","ìˆ˜","ì¢€"]
all_words = []
parts = ["Noun"]
for n in range(len(survey)):
    text = survey["comment"].iloc[n]
    words = twt.pos(text)
    words_arr = []
    for i in words:
        if i == "EOS" or i == "": continue
        word_tmp = i[0]
        part = i[1]
        if not (part in parts):continue
        if word_tmp in stop_words:continue
        words_arr.append(word_tmp)
    all_words.extend(words_arr)
print(all_words)
```
![alt text](/assets/img_20241102/image-48.png)

### ì œì™¸ ë‹¨ì–´ ì œê±° í›„ ë‚¨ì€ ë¹ˆì¶œ ë‹¨ì–´

```py
all_words_df = pd.DataFrame({"words":all_words, "count":len(all_words)*[1]})
all_words_df = all_words_df.groupby("words").sum()
all_words_df.sort_values("count",ascending=False).head()
```
![alt text](/assets/img_20241102/image-49.png)

# 098.ê³ ê°ë§Œì¡±ë„ì™€ ìì£¼ ë‚˜ì˜¤ëŠ” ë‹¨ì–´ì˜ ê´€ê³„ë¥¼ ì‚´í´ë³´ì

### ë‹¨ì–´ì™€ ê³ ê°ë§Œì¡±ë„ ì¶”ì¶œ

```py
stop_words = ["ë”","ìˆ˜","ì¢€"]
parts = ["Noun"]
all_words = []
satisfaction = []
for n in range(len(survey)):
    text = survey["comment"].iloc[n]
    words = twt.pos(text)
    words_arr = []
    for i in words:
        if i == "EOS" or i == "": continue
        word_tmp = i[0]
        part = i[1]
        if not (part in parts):continue
        if word_tmp in stop_words:continue
        words_arr.append(word_tmp)
        satisfaction.append(survey["satisfaction"].iloc[n])
    all_words.extend(words_arr)
all_words_df = pd.DataFrame({"words":all_words, "satisfaction":satisfaction, "count":len(all_words)*[1]})
all_words_df.head()
```
![alt text](/assets/img_20241102/image-50.png)

### ê³ ê°ë§Œì¡±ë„ ê³„ì‚°

```py
words_satisfaction = all_words_df.groupby("words").mean()["satisfaction"]
words_count = all_words_df.groupby("words").sum()["count"]
words_df = pd.concat([words_satisfaction, words_count], axis=1)
words_df.head()
```
![alt text](/assets/img_20241102/image-51.png)

### ê³ ê°ë§Œì¡±ë„ê°€ ë†’ì€/ë‚®ì€ ë‹¨ì–´

- ì†Œìˆ˜ ì˜ê²¬ ë§ê³  countê°€ 3 ì´ìƒì¸ ë°ì´í„°ë§Œ!

```py
words_df = words_df.loc[words_df["count"]>=3]
words_df.sort_values("satisfaction", ascending=False).head()
```
![alt text](/assets/img_20241102/image-52.png)

```py
words_df.sort_values("satisfaction").head()
```
![alt text](/assets/img_20241102/image-53.png)

# 099.ì˜ê²¬ì„ íŠ¹ì§•ìœ¼ë¡œ í‘œí˜„í•´ ë³´ì

### ì˜ê²¬ íŠ¹ì§• ì‘ì„±

```py
parts = ["Noun"]
all_words_df = pd.DataFrame()
satisfaction = []
for n in range(len(survey)):
    text = survey["comment"].iloc[n]
    words = twt.pos(text)
    words_df = pd.DataFrame()
    for i in words:
        if i == "EOS" or i == "": continue
        word_tmp = i[0]
        part = i[1]
        if not (part in parts):continue
        words_df[word_tmp] = [1]
    all_words_df = pd.concat([all_words_df, words_df] ,ignore_index=True)
all_words_df.head()
```
![alt text](/assets/img_20241102/image-54.png)

- ì˜ê²¬ì— ã…—í•¨ëœ ë‹¨ì–´ëŠ” 1 / ê·¸ ì™¸ì—ëŠ” ê²°ì¸¡ì¹˜ê°€ ëŒ€ì…

### ì˜ê²¬ì˜ íŠ¹ì§• ê²°ì¸¡ì¹˜ ì²˜ë¦¬

```py
all_words_df = all_words_df.fillna(0)
all_words_df.head()
```
![alt text](/assets/img_20241102/image-55.png)

# 100.ë¹„ìŠ·í•œ ì„¤ë¬¸ì§€ë¥¼ ì°¾ì•„ë³´ì

### íƒ€ê¹ƒ ì˜ê²¬ ì¶”ì¶œ

```py
print(survey["comment"].iloc[2])
target_text = all_words_df.iloc[2]
print(target_text)
```
![alt text](/assets/img_20241102/image-56.png)

### ìœ ì‚¬ë„ ê³„ì‚°

```py
import numpy as np
cos_sim = []
for i in range(len(all_words_df)):
    cos_text = all_words_df.iloc[i]
    cos = np.dot(target_text, cos_text) / (np.linalg.norm(target_text) * np.linalg.norm(cos_text))
    # np.linalg.norm: ë°±í„°ì˜ ê¸¸ì´ ê³„ì‚°
    cos_sim.append(cos)
all_words_df["cos_sim"] = cos_sim
all_words_df.sort_values("cos_sim",ascending=False).head()
```
![alt text](/assets/img_20241102/image-57.png)
![alt text](/assets/img_20241102/image-58.png)

### ìœ ì‚¬ ì˜ê²¬ ì¶œë ¥

```py
print(survey["comment"].iloc[2])
print(survey["comment"].iloc[15])
print(survey["comment"].iloc[24])
```
![alt text](/assets/img_20241102/image-59.png)