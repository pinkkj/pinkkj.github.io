---
excerpt: "[5-2] ResNet êµ¬í˜„"
name: J
writer: J
categories: [ê°•ì˜ ì •ë¦¬, ì‹¤ì „ ê¸°ê³„ í•™ìŠµ] # [ë©”ì¸ ì¹´í…Œê³ ë¦¬, ì„œë¸Œ ì¹´í…Œê³ ë¦¬]
tags:
  - []

toc: true
toc_sticky: true

date: 2025-11-06
last_modified_at: 2024-11-06

# --- ì•„ë˜ ë¶€í„° content
---
# Q1. Batch Normalization ì™¸ ë‹¤ë¥¸ Normalization ë°©ë²•?
## 1. LayerNorm
[LayerNorm](https://docs.pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html)

```py
class torch.nn.LayerNorm(normalized_shape, eps=1e-05, elementwise_affine=True, bias=True, device=None, dtype=None)
```

### ğŸ§© Layer Normalization (ì¸µ ì •ê·œí™”)
- Layer Normalizationì€ ì…ë ¥ ë¯¸ë‹ˆë°°ì¹˜ì— ëŒ€í•´ ì •ê·œí™”ë¥¼ ì ìš©í•˜ëŠ” ì¸µì´ì•¼.
ì¦‰, ê° ìƒ˜í”Œ(í•œ ë°°ì¹˜ ì•ˆì˜ í•œ ë°ì´í„°)ì— ëŒ€í•´ í‰ê· ê³¼ ë¶„ì‚°ì„ êµ¬í•´ ì •ê·œí™”í•´ ì£¼ëŠ” ë°©ì‹ì´ì•¼.

### âš™ï¸ ìˆ˜ì‹

![alt text]({{ '/assets/img_20251106/image.png' | relative_url }})

- E[x] : ì…ë ¥ì˜ í‰ê· 
- Var[x] : ì…ë ¥ì˜ ë¶„ì‚°
- Îµ (epsilon) : 0ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ê²ƒì„ ë°©ì§€í•˜ê¸° ìœ„í•œ ì‘ì€ ìƒìˆ˜
- Î³ (gamma) : í•™ìŠµ ê°€ëŠ¥í•œ ìŠ¤ì¼€ì¼(ê°€ì¤‘ì¹˜)
- Î² (beta) : í•™ìŠµ ê°€ëŠ¥í•œ ì‹œí”„íŠ¸(í¸í–¥)

### ì •ê·œí™” ë²”ìœ„
- normalized_shapeì— ë”°ë¼ ì •ê·œí™”ë˜ëŠ” ì°¨ì›ì´ ê²°ì •ë¼.
  - ì˜ˆë¥¼ ë“¤ì–´, normalized_shape = (3, 5) ë¼ë©´ ì…ë ¥ í…ì„œì˜ ë§ˆì§€ë§‰ ë‘ ì°¨ì›(-2, -1) ì„ ê¸°ì¤€ìœ¼ë¡œ í‰ê· ê³¼ ë¶„ì‚°ì„ ê³„ì‚°í•´. ì¦‰, input.mean((-2, -1)) ê³¼ ê°™ì€ ì—°ì‚°ì´ ì¼ì–´ë‚˜ëŠ” ê±°ì•¼.

### ğŸ§  í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° (Î³, Î²)
- elementwise_affine=Trueì¼ ê²½ìš°, Î³ì™€ Î²ëŠ” í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°ê°€ ë¼.
- ì´ë•Œ Î³ì™€ Î²ì˜ í¬ê¸°ëŠ” normalized_shapeì™€ ë™ì¼í•˜ê³ ,
  - Î³ëŠ” 1ë¡œ ì´ˆê¸°í™”ë˜ê³ 
  - Î²ëŠ” 0ìœ¼ë¡œ ì´ˆê¸°í™”ë¼.
  - ì´ë“¤ì€ ê° ìš”ì†Œ(element) ë§ˆë‹¤ ë³„ë„ë¡œ ì ìš©ë˜ëŠ” per-element scale, biasì•¼.

### ğŸ§® ë¶„ì‚° ê³„ì‚°
ë¶„ì‚°ì€ biased estimator (í¸í–¥ëœ ì¶”ì •ê¸°)ë¡œ ê³„ì‚°ë¼.
ì¦‰, torch.var(input, unbiased=False) ì™€ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ìˆ˜í–‰ë¼

### ğŸ’¡ BatchNorm / InstanceNorm ê³¼ì˜ ì°¨ì´ì 

| êµ¬ë¶„ | ì •ê·œí™” ë²”ìœ„ | í•™ìŠµ íŒŒë¼ë¯¸í„°|
|------|------------|-------------|
|Batch Normalization|ë°°ì¹˜ ì „ì²´|ì±„ë„ ë‹¨ìœ„|
|Instance Normalization|ê° ìƒ˜í”Œì˜ ì±„ë„ë³„|ì±„ë„ ë‹¨ìœ„|
|Layer Normalization|ê° ìƒ˜í”Œì˜ ëª¨ë“  feature|ìš”ì†Œ ë‹¨ìœ„|

### ì˜ˆì‹œ
```py
# NLP Example
batch, sentence_length, embedding_dim = 20, 5, 10
embedding = torch.randn(batch, sentence_length, embedding_dim)
layer_norm = nn.LayerNorm(embedding_dim)
# Activate module
layer_norm(embedding)
# Image Example
N, C, H, W = 20, 5, 10, 10
input = torch.randn(N, C, H, W)
# Normalize over the last three dimensions (i.e. the channel and spatial dimensions)
# as shown in the image below
layer_norm = nn.LayerNorm([C, H, W])
output = layer_norm(input)
```
or
```py
nn.GroupNorm(1, out_channels)
```
![alt text]({{ '/assets/img_20251106/image-2.png' | relative_url }})
![alt text]({{ '/assets/img_20251106/image-1.png' | relative_url }})

## 2. GroupNorm
### ğŸ§© 1ï¸âƒ£ ê¸°ë³¸ ê°œë…

Group Normalization (GN) ì€ ì…ë ¥ì˜ ì±„ë„ì„ ì—¬ëŸ¬ â€œê·¸ë£¹â€ìœ¼ë¡œ ë‚˜ëˆ ì„œ,
ê° ê·¸ë£¹ ì•ˆì—ì„œ í‰ê· ê³¼ ë¶„ì‚°ì„ ê³„ì‚°í•´ ì •ê·œí™”í•˜ëŠ” ë°©ë²•ì´ì•¼.

ìˆ˜ì‹ì€ LayerNormê³¼ ê±°ì˜ ê°™ì•„. ë‹¨, í‰ê·  E[x]ì™€ ë¶„ì‚° Var[x]ì„ â€œê° ê·¸ë£¹ë³„ë¡œâ€ ê³„ì‚°í•œë‹¤ëŠ” ê²Œ í•µì‹¬ ì°¨ì´ì•¼.

### âš™ï¸ 2ï¸âƒ£ ì–´ë–»ê²Œ ê·¸ë£¹ì„ ë‚˜ëˆ„ëŠ”ê°€?
ì…ë ¥ í…ì„œì˜ shape:
```mathematica
(N, C, H, W)
```
- N: ë°°ì¹˜ í¬ê¸° (ì •ê·œí™” ê³„ì‚°ì—ëŠ” í¬í•¨ ì•ˆ ë¨)
- C: ì±„ë„ ìˆ˜ (ì˜ˆ: 64)
- H, W: ê³µê°„ ì°¨ì› (ì´ë¯¸ì§€ì˜ ë†’ì´, ë„ˆë¹„)

|num_groups|ê·¸ë£¹ êµ¬ì„±|ì •ê·œí™” ë²”ìœ„|
|----------|--------|-----------|
|1         |ëª¨ë“  ì±„ë„ì´ í•œ ê·¸ë£¹|LayerNormê³¼ ë™ì¼|
|C|ê° ì±„ë„ì´ í•œ ê·¸ë£¹|InstanceNormê³¼ ë™ì¼|
|ì¤‘ê°„ ê°’(ì˜ˆ: 32, 8 ë“±) | Cë¥¼ num_groupsë¡œ ë‚˜ëˆ”|GN ê³ ìœ  í˜•íƒœ|

### ğŸ§® 3ï¸âƒ£ ì˜ˆì‹œë¡œ ë³´ê¸°
- ì˜ˆë¥¼ ë“¤ì–´ ì…ë ¥ì´ (N=2, C=8, H=4, W=4)ì´ê³ ,
num_groups=4ë¼ë©´:
  - ì´ 8ì±„ë„ì„ 4ê°œ ê·¸ë£¹ìœ¼ë¡œ ë‚˜ëˆ” â†’ ê·¸ë£¹ë‹¹ 2ì±„ë„ì”©
  - ê° ê·¸ë£¹ ì•ˆì˜ (2 x 4 x 4) ê°’ë“¤ë¡œ í‰ê· ê³¼ ë¶„ì‚° ê³„ì‚°
  - ê·¸ê±¸ë¡œ ì •ê·œí™”

  ì¦‰, ê° ê·¸ë£¹ì´ ë…ë¦½ì ìœ¼ë¡œ í‰ê·  0, ë¶„ì‚° 1ë¡œ ë§ì¶°ì§€ëŠ” ê±°ì•¼.

### ğŸ“Š 4ï¸âƒ£ BatchNorm / LayerNorm / GroupNorm ë¹„êµ

![alt text]({{ '/assets/img_20251106/image-3.png' | relative_url }})

## 3. InstanceNorm
- GroupNormì˜ Cë¥¼ Cë¡œ í•œê²ƒ!
- ì¦‰ í•œ sample ë‹¹ í•˜ë‚˜ì˜ channelì„ ê¸°ì¤€ìœ¼ë¡œ ì •ê·œí™”

## 4. RMS(ì œê³±í‰ê· ì œê³±ê·¼)
### í•µì‹¬ ìš”ì•½
- ìˆ˜ì‹
  - í‰ê· ì„ ë¹¼ì§€ ì•Šê³  í‘œì¤€í¸ì°¨ ëŒ€ì‹  RMSë¡œë§Œ ìŠ¤ì¼€ì¼ë§
  - Î³ë§Œ ìˆìŒ(ê¸°ë³¸ì ìœ¼ë¡œ bias/Î² ì—†ìŒ)
![alt text]({{ '/assets/img_20251106/image-4.png' | relative_url }})

- ì •ê·œí™” ì¶•: normalized_shapeì˜ ë§ˆì§€ë§‰ Dê°œ ì°¨ì›(=LayerNormê³¼ ë™ì¼í•œ ì¶• ì„ íƒ ë°©ì‹)
- ì¥ì : ê³„ì‚° ë‹¨ìˆœ(ë¹ ë¦„), ì•ˆì •ì , ëŒ€í˜• Transformer/LLMì—ì„œ ìì£¼ ì‚¬ìš©(LLaMAë¥˜ ë“±)

### ì–¸ì œ ì“°ë‹ˆ?
- Transformer/ViT/MLP ë¸”ë¡ì˜ hidden ì°¨ì› ì •ê·œí™”ì— ì•„ì£¼ í”í•¨: nn.RMSNorm(hidden_dim)
- CNN(NCHW)ì—ì„œëŠ” ë“œë­„(ëŒ€ì‹  BN/GN/LN ë” í”í•¨). ê·¸ë˜ë„ ì“°ë ¤ë©´ ì¶•ì„ ë§ì¶°ì¤˜ì•¼ í•¨(ì•„ë˜ ì½”ë“œ ì°¸ê³ ).

### normalized_shape ì´í•´ (ì…ë ¥ (N, H, W, C) & (N, C, H, W))
- ì…ë ¥ì´ (N, *, D)ê¼´ì´ë©´ ë³´í†µ normalized_shape=(D,)ë¡œ ë§ˆì§€ë§‰ ì°¨ì› ê¸°ì¤€ ì •ê·œí™”
- ì˜ˆ: Transformer ì…ë ¥ (N, seq_len, hidden_dim) â†’ RMSNorm(hidden_dim)
- ì´ë¯¸ì§€ëŠ” PyTorchê°€ ê¸°ë³¸ NCHWì´ë¯€ë¡œ, ë§ˆì§€ë§‰ ì°¨ì›ì´ ì±„ë„ì´ ì•„ë‹ˆê¸° ë•Œë¬¸ì— ë°”ë¡œ ì“°ë©´ ì˜ë„ì™€ ë‹¤ë¦„
â†’ ê°„ë‹¨í•œ ë˜í¼ë¡œ NHWCë¡œ ë°”ê¿” ì ìš©í•˜ë©´ ë¼

```py
class RMSNorm2d(nn.Module):
    def __init__(self, num_channels, eps=None, elementwise_affine=True):
        super().__init__()
        self.norm = nn.RMSNorm(normalized_shape=num_channels, eps=eps, elementwise_affine=elementwise_affine)

    def forward(self, x):          
        x = x.permute(0, 2, 3, 1)  
        x = self.norm(x)          
        x = x.permute(0, 3, 1, 2)  
        return x
      
# Resnet ë¸”ë¡ì—ì„œ..
self.residual_function = nn.Sequential(
    nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),
    RMSNorm2d(out_channels),   
    nn.ReLU(inplace=True),
    nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False),
    RMSNorm2d(out_channels),   
)

...
if stride != 1 or in_channels != out_channels:
    self.shortcut = nn.Sequential(
        nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),
        RMSNorm2d(out_channels),  
    )
```

# Q2. ResNet32 êµ¬í˜„
```py
import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
CIFAR10_MEAN = (0.4914, 0.4822, 0.4465)
CIFAR10_STD  = (0.2470, 0.2435, 0.2616)
num_epochs = 80
learning_rate = 0.001

transform = transforms.Compose([
    transforms.Pad(4),
    transforms.RandomHorizontalFlip(),
    transforms.RandomCrop(32),
    transforms.ToTensor(),
    transforms.Normalize(CIFAR10_MEAN, CIFAR10_STD),
])
test_transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(CIFAR10_MEAN, CIFAR10_STD),   # â† í…ŒìŠ¤íŠ¸ì—ë„
])

train_dataset = torchvision.datasets.CIFAR10(root='../../data/',
                                             train = True,
                                             transform=transform,
                                             download = True)
test_dataset = torchvision.datasets.CIFAR10(root='../../data/',
                                            train = False,
                                            transform = test_transform)

train_loader = torch.utils.data.DataLoader(dataset=train_dataset,
                                           batch_size = 100,
                                           shuffle=True)
test_loader = torch.utils.data.DataLoader(dataset = test_dataset,
                                          batch_size=100,
                                          shuffle=False)


# Basic block
class BasicBlock(nn.Module):
  def __init__(self, in_channels, out_channels, stride = 1):
    super().__init__()

    self.residual_function = nn.Sequential(
        nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1,bias=False),
        nn.BatchNorm2d(out_channels), #layernormì¼ë• nn.GroupNorm(1, out_channels) / Groupnormì¼ë• nn.GroupNorm(32, out_channels) / instancenorm ì¼ë•Œ nn.GroupNorm(out_channels, out_channels)
        nn.ReLU(),
        nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False),
        nn.BatchNorm2d(out_channels),
    )

    self.shortcut = nn.Sequential()

    if stride != 1 or in_channels != out_channels:
      self.shortcut = nn.Sequential(
          nn.Conv2d(in_channels, out_channels, kernel_size=1, stride = stride, bias = False),
          nn.BatchNorm2d(out_channels),
      )
    
    self.relu = nn.ReLU()
  
  def forward(self, x):
    x = self.residual_function(x) + self.shortcut(x)
    x = self.relu(x)
    return x

class ResNet(nn.Module):
  def __init__(self, block, num_block, num_classes = 10, init_weight = True):
    super().__init__()

    self.in_channels = 64

    self.conv1 = nn.Sequential(
        nn.Conv2d(3, 64, kernel_size = 7, stride = 2, padding = 3, bias = False),
        nn.BatchNorm2d(64),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
    )

    self.conv2_x = self._make_layer(block, 64, num_block[0], 1)
    self.conv3_x = self._make_layer(block, 128, num_block[1], 2)
    self.conv4_x = self._make_layer(block, 256, num_block[2], 2)
    self.conv5_x = self._make_layer(block, 512, num_block[3], 2)

    self.avg_pool = nn.AdaptiveAvgPool2d((1,1))
    self.fc = nn.Linear(512, num_classes)
  
  def _make_layer(self, block, out_channels, num_blocks, stride):
    strides = [stride] + [1] * (num_blocks - 1)
    layers = []
    for stride in strides:
      layers.append(block(self.in_channels, out_channels, stride))
      self.in_channels = out_channels
    
    return nn.Sequential(*layers)
  
  def forward(self, x):
    output = self.conv1(x)
    output = self.conv2_x(output)
    x = self.conv3_x(output)
    x = self.conv4_x(x)
    x = self.conv5_x(x)
    x = self.avg_pool(x)
    x = x.view(x.size(0), -1)
    x = self.fc(x)
    return x

model = ResNet(BasicBlock, [3,4,6,3]).to(device)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)

def update_lr(optimizer, lr):
  for param_group in optimizer.param_groups:
    param_group['lr'] = lr

total_step = len(train_loader)
curr_lr = learning_rate

model.train()
for epoch in range(num_epochs):
  for i, (images, labels) in enumerate(train_loader):
    images = images.to(device)
    labels = labels.to(device)
    outputs = model(images)
    loss = criterion(outputs, labels)

    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    if (i+1) % 100 == 0:
      print("Epoch [{}/{}], step [{}/{}], Loss: {:4f}".format(epoch+1, num_epochs, i+1, total_step, loss.item()))

  if (epoch+1) % 20 == 0:
    curr_lr /= 3
    update_lr(optimizer, curr_lr)

model.eval()
with torch.no_grad():
  correct = 0
  total = 0
  for images, labels in test_loader:
    images = images.to(device)
    labels = labels.to(device)
    outputs = model(images)
    _, predicted = torch.max(outputs.data, 1)
    total += labels.size(0)
    correct += (predicted == labels).sum().item()

  print('Accuracy of the odel on the test images: {} %'.format(100*correct/total))
```

# Q3. BottleNeck ì´ìš©
- 50ì¸µ ì´ìƒì˜ ResNetì€ ë§¤ê°œë³€ìˆ˜ ì‚¬ìš© ìµœì†Œí™” ìœ„í•´ ì´ìš©
- BottleNeck: Conv 1x1ì„ ì´ìš©í•˜ì—¬ ì±„ë„ ì°¨ì› ì¶•ì†Œ í›„ Conv3x3ì„ ì´ìš© -> ë‹¤ì‹œ Conv1x1ë¡œ ì±„ë„ ì°¨ì›ì„ ë³µì›í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ë™ì‘í•˜ëŠ” block
- ì°¸ê³ : [[ë…¼ë¬¸ êµ¬í˜„]pytorchë¡œ ResNet(2015) êµ¬í˜„í•˜ê³  í•™ìŠµí•˜ê¸°](https://deep-learning-study.tistory.com/534)

### Bottleneck Design

ì‹ ê²½ë§ì´ ê¹Šì–´ì§€ë©´ í•™ìŠµí•˜ëŠ”ë° ì†Œìš”ë˜ëŠ” ì‹œê°„ì€ ì—„ì²­ ì˜¤ë˜ ê±¸ë¦´ ê²ƒ ì…ë‹ˆë‹¤. bottleneck designì€ ë‹¤ìŒê³¼ ê°™ì´ ì‹ ê²½ë§ì˜ ë³µì¡ë„ë¥¼ ê°ì†Œí•˜ê¸° ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤.

![alt text]({{ '/assets/img_20251106/image-5.png' | relative_url }})

- NINê³¼ GoogLeNetì—ì„œ ì œì•ˆ
- 1x1 convëŠ” ì‹ ê²½ë§ì˜ ì„±ëŠ¥ì„ ê°ì†Œì‹œí‚¤ì§€ ì•Šê³  íŒŒë¼ë¯¸í„° ìˆ˜ë¥¼ ê°ì†Œì‹œí‚µë‹ˆë‹¤. 

### Code

[github.com/weiaicunzai/pytorch-cifar100](https://github.com/weiaicunzai/pytorch-cifar100/blob/master/models/resnet.py)

```py
"""resnet in pytorch



[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun.

    Deep Residual Learning for Image Recognition
    https://arxiv.org/abs/1512.03385v1
"""

import torch
import torch.nn as nn

class BasicBlock(nn.Module):
    """Basic Block for resnet 18 and resnet 34

    """

    #BasicBlock and BottleNeck block
    #have different output size
    #we use class attribute expansion
    #to distinct
    expansion = 1

    def __init__(self, in_channels, out_channels, stride=1):
        super().__init__()

        #residual function
        self.residual_function = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels * BasicBlock.expansion, kernel_size=3, padding=1, bias=False),
            nn.BatchNorm2d(out_channels * BasicBlock.expansion)
        )

        #shortcut
        self.shortcut = nn.Sequential()

        #the shortcut output dimension is not the same with residual function
        #use 1*1 convolution to match the dimension
        if stride != 1 or in_channels != BasicBlock.expansion * out_channels:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_channels, out_channels * BasicBlock.expansion, kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(out_channels * BasicBlock.expansion)
            )

    def forward(self, x):
        return nn.ReLU(inplace=True)(self.residual_function(x) + self.shortcut(x))

class BottleNeck(nn.Module):
    """Residual block for resnet over 50 layers

    """
    expansion = 4
    def __init__(self, in_channels, out_channels, stride=1):
        super().__init__()
        self.residual_function = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, stride=stride, kernel_size=3, padding=1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels * BottleNeck.expansion, kernel_size=1, bias=False),
            nn.BatchNorm2d(out_channels * BottleNeck.expansion),
        )

        self.shortcut = nn.Sequential()

        if stride != 1 or in_channels != out_channels * BottleNeck.expansion:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_channels, out_channels * BottleNeck.expansion, stride=stride, kernel_size=1, bias=False),
                nn.BatchNorm2d(out_channels * BottleNeck.expansion)
            )

    def forward(self, x):
        return nn.ReLU(inplace=True)(self.residual_function(x) + self.shortcut(x))

class ResNet(nn.Module):

    def __init__(self, block, num_block, num_classes=100):
        super().__init__()

        self.in_channels = 64

        self.conv1 = nn.Sequential(
            nn.Conv2d(3, 64, kernel_size=3, padding=1, bias=False),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True))
        #we use a different inputsize than the original paper
        #so conv2_x's stride is 1
        self.conv2_x = self._make_layer(block, 64, num_block[0], 1)
        self.conv3_x = self._make_layer(block, 128, num_block[1], 2)
        self.conv4_x = self._make_layer(block, 256, num_block[2], 2)
        self.conv5_x = self._make_layer(block, 512, num_block[3], 2)
        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))
        self.fc = nn.Linear(512 * block.expansion, num_classes)

    def _make_layer(self, block, out_channels, num_blocks, stride):
        """make resnet layers(by layer i didnt mean this 'layer' was the
        same as a neuron netowork layer, ex. conv layer), one layer may
        contain more than one residual block

        Args:
            block: block type, basic block or bottle neck block
            out_channels: output depth channel number of this layer
            num_blocks: how many blocks per layer
            stride: the stride of the first block of this layer

        Return:
            return a resnet layer
        """

        # we have num_block blocks per layer, the first block
        # could be 1 or 2, other blocks would always be 1
        strides = [stride] + [1] * (num_blocks - 1)
        layers = []
        for stride in strides:
            layers.append(block(self.in_channels, out_channels, stride))
            self.in_channels = out_channels * block.expansion

        return nn.Sequential(*layers)

    def forward(self, x):
        output = self.conv1(x)
        output = self.conv2_x(output)
        output = self.conv3_x(output)
        output = self.conv4_x(output)
        output = self.conv5_x(output)
        output = self.avg_pool(output)
        output = output.view(output.size(0), -1)
        output = self.fc(output)

        return output

def resnet18():
    """ return a ResNet 18 object
    """
    return ResNet(BasicBlock, [2, 2, 2, 2])

def resnet34():
    """ return a ResNet 34 object
    """
    return ResNet(BasicBlock, [3, 4, 6, 3])

def resnet50():
    """ return a ResNet 50 object
    """
    return ResNet(BottleNeck, [3, 4, 6, 3])

def resnet101():
    """ return a ResNet 101 object
    """
    return ResNet(BottleNeck, [3, 4, 23, 3])

def resnet152():
    """ return a ResNet 152 object
    """
    return ResNet(BottleNeck, [3, 8, 36, 3])
```

# Q4. í•™ìŠµ ê°€ì¤‘ì¹˜ ì´ˆê¸°í™” (Xavier_normal ë°©ë²•, kaiming_normal ë°©ë²•)
## ğŸ“Œ ì™œ ì´ˆê¸°í™”ê°€ ì¤‘ìš”í• ê¹Œ?
- ì‹ ê²½ë§ í•™ìŠµ ì´ˆê¸°ì— ê°€ì¤‘ì¹˜ ë¶„í¬ê°€ ë„ˆë¬´ í¬ê±°ë‚˜ ì‘ìœ¼ë©´<br>
âœ ê¸°ìš¸ê¸° ì†Œì‹¤(vanishing) ë˜ëŠ” ê¸°ìš¸ê¸° í­ë°œ(exploding) ë°œìƒ
- ì ì ˆí•œ ì´ˆê¸°í™”ëŠ” ì…ë ¥/ì¶œë ¥ varianceë¥¼ ì¼ì •í•˜ê²Œ ìœ ì§€ â†’ ì•ˆì •ì ì¸ í•™ìŠµ
<br><br>

PyTorchì—ì„œëŠ” ì´ëŸ° ì´ˆê¸°í™” ì „ëµì„ ì‰½ê²Œ ì“¸ ìˆ˜ ìˆê²Œ torch.nn.init ëª¨ë“ˆì„ ì œê³µí•©ë‹ˆë‹¤.
ëª¨ë“  í•¨ìˆ˜ëŠ” torch.no_grad() ëª¨ë“œì—ì„œ ì‹¤í–‰ë¼ì„œ autogradì— ê¸°ë¡ë˜ì§€ ì•Šì•„ìš”.
## ğŸ”¹ ì£¼ìš” ì´ˆê¸°í™” í•¨ìˆ˜ ìš”ì•½
| í•¨ìˆ˜                                           | ì—­í•                                   | ìˆ˜ì‹ / íŠ¹ì§•                                                      |
| -------------------------------------------- | ----------------------------------- | ------------------------------------------------------------ |
| **`nn.init.constant_`**                      | í…ì„œë¥¼ **íŠ¹ì • ìƒìˆ˜ ê°’**ìœ¼ë¡œ ì±„ì›€                | `tensor[:] = val`                                            |
| **`nn.init.ones_`**, **`nn.init.zeros_`**    | 1 ë˜ëŠ” 0ìœ¼ë¡œ ì±„ì›€                         | biasë¥¼ 0ìœ¼ë¡œ ì´ˆê¸°í™”í•  ë•Œ ìì£¼ ì‚¬ìš©                                       |
| **`nn.init.uniform_(a, b)`**                 | **ê· ë“±ë¶„í¬ U(a, b)**ì—ì„œ ìƒ˜í”Œë§              | ì˜ˆ: `U(-0.1, 0.1)`                                            |
| **`nn.init.normal_(mean, std)`**             | **ì •ê·œë¶„í¬ N(mean, stdÂ²)**ì—ì„œ ìƒ˜í”Œë§        | ì˜ˆ: `N(0, 0.01)`                                              |
| **`nn.init.trunc_normal_(mean, std, a, b)`** | **ì ˆë‹¨ ì •ê·œë¶„í¬** (ê°’ì´ [a,b] ë²”ìœ„ ì•ˆì—ë§Œ)       | transformer ê³„ì—´ì—ì„œ ìì£¼ ì‚¬ìš©                                       |
| **`nn.init.eye_`**                           | **í•­ë“± í–‰ë ¬(I)** ë¡œ ì´ˆê¸°í™”                  | Linear layerì— ê°€ë” ì‚¬ìš©                                          |
| **`nn.init.dirac_`**                         | Conv ë ˆì´ì–´ì—ì„œ **ì…ë ¥=ì¶œë ¥ ì±„ë„ ì—°ê²° ìœ ì§€**       | ID ë§¤í•‘ íš¨ê³¼                                                     |
| **`nn.init.sparse_`**                        | í…ì„œë¥¼ **í¬ì†Œ í–‰ë ¬(sparse)** ë¡œ ì´ˆê¸°í™”         | ê° columnì— ì¼ë¶€ ê°’ë§Œ N(0, stdÂ²)ë¡œ ì±„ì›€                               |
| **`nn.init.orthogonal_`**                    | ê°€ì¤‘ì¹˜ë¥¼ **ì§êµí–‰ë ¬**ë¡œ ì´ˆê¸°í™”                  | ì¶œë ¥ ê°„ ìƒê´€ê´€ê³„ ìµœì†Œí™”                                                |
| **`nn.init.xavier_uniform_`**                | Glorot uniform, **ì…ì¶œë ¥ variance ê· í˜•** | `U(-a, a)` where `a = gain * sqrt(6/(fan_in + fan_out))`     |
| **`nn.init.xavier_normal_`**                 | Glorot normal                       | `N(0, stdÂ²)` where `std = gain * sqrt(2/(fan_in + fan_out))` |
| **`nn.init.kaiming_uniform_`**               | He uniform (ReLUìš©)                  | `U(-bound, bound)` with `bound = gain * sqrt(3/fan_in)`      |
| **`nn.init.kaiming_normal_`**                | He normal (ReLUìš©)                   | `N(0, stdÂ²)` where `std = gain / sqrt(fan_in)`               |
| **`nn.init.calculate_gain()`**               | **í™œì„±í•¨ìˆ˜ë³„ gain (ìŠ¤ì¼€ì¼ë§ ìƒìˆ˜)** ê³„ì‚°         | ì˜ˆ: ReLU=âˆš2, Tanh=5/3, LeakyReLU=âˆš(2/(1+Î±Â²))                  |
## âš™ï¸ calculate_gain() ìì„¸íˆ ë³´ê¸°

í™œì„± í•¨ìˆ˜ë³„ë¡œ ì…ë ¥ ë¶„ì‚°ì„ ìœ ì§€í•˜ë ¤ë©´ gain(ë³´ì • ê³„ìˆ˜)ì´ ë‹¬ë¼ì§‘ë‹ˆë‹¤.

| ë¹„ì„ í˜• í•¨ìˆ˜                  | gain ê°’       | ë¹„ê³                                 |
| ----------------------- | ------------ | --------------------------------- |
| `'linear'` / `'conv2d'` | 1            | ê¸°ë³¸                                |
| `'sigmoid'`             | 1            |                                   |
| `'tanh'`                | 5/3 â‰ˆ 1.6667 |                                   |
| `'relu'`                | âˆš2 â‰ˆ 1.414   | **He ì´ˆê¸°í™”ì˜ í•µì‹¬**                    |
| `'leaky_relu'`          | âˆš(2/(1+Î±Â²))  | Î±=0.01ì´ë©´ â‰ˆ1.414                   |
| `'selu'`                | 3/4          | í•˜ì§€ë§Œ self-normalizingì—ì„œëŠ” linear ê¶Œì¥ |

```py
gain = nn.init.calculate_gain('relu')
w = torch.empty(64, 3, 3, 3)
nn.init.xavier_uniform_(w, gain=gain)
```

## Xavier_normal ë°©ë²•
- ë…¼ë¬¸: Glorot & Bengio (2010)
- ëª©í‘œ: ì…ì¶œë ¥ variance ë™ì¼í•˜ê²Œ ìœ ì§€
- ì ìš©: Sigmoid, Tanh ê³„ì—´. ReLUì—ëŠ” Kaimingì´ ë” ì í•©.
- ê³µì‹:

![alt text]({{ '/assets/img_20251106/image-6.png' | relative_url }})

```py
nn.init.xavier_uniform_(layer.weight, gain=nn.init.calculate_gain('relu'))
```
## âš¡ Kaiming (He) ì´ˆê¸°í™”
- ë…¼ë¬¸: He et al., 2015
- ëª©í‘œ: ReLU í•¨ìˆ˜ì—ì„œ ì…ë ¥ ë¶„ì‚° ë³´ì¡´
- ê³µì‹:

![alt text]({{ '/assets/img_20251106/image-7.png' | relative_url }})

- ë‘ ë²„ì „ ìˆìŒ:
  - kaiming_uniform_: U(-bound, bound)
  - kaiming_normal_: N(0, stdÂ²)

```py
nn.init.kaiming_normal_(conv.weight, mode='fan_out', nonlinearity='relu')
```

### 1) modeê°€ ë­ëƒ?

Kaiming(He) ì´ˆê¸°í™”ì—ì„œ ë¶„ì‚°ì„ ì–´ë””ì—ì„œ ë³´ì¡´í• ì§€ë¥¼ ê³ ë¥´ëŠ” ì˜µì…˜ì´ì•¼.
- mode='fan_in' â†’ ìˆœì „íŒŒ(forward) ì—ì„œ ë¶„ì‚° ë³´ì¡´ (ê°€ì¥ í”í•¨, ê¸°ë³¸ê°’)
- mode='fan_out' â†’ ì—­ì „íŒŒ(backward) ì—ì„œ ë¶„ì‚° ë³´ì¡´

ëŒ€ë¶€ë¶„ ReLU ê³„ì—´ ë„¤íŠ¸ì›Œí¬ì—ì„  fan_in ì„ ì”€.
íŠ¹ì • ì´ìœ (ì˜ˆ: Deconv/íŠ¹ì • ì•„í‚¤í…ì²˜ì˜ ì•ˆì •ì„±)ë¥¼ ìœ„í•´ ì—­ì „íŒŒ ë¶„ì‚° ë³´ì¡´ì´ í•„ìš”í•˜ë©´ fan_out.

### 2) kaiming_uniform_ì˜ boundì™€ kaiming_normal_ì˜ std

Kaiming ì´ˆê¸°í™”ì˜ ëª©í‘œ: ReLU/LeakyReLU ê°™ì€ ë¹„ëŒ€ì¹­ í™œì„±í™”ì—ì„œë„ ì‹ í˜¸ ë¶„ì‚°ì´ ì¸µì„ ì§€ë‚˜ë©° ìœ ì§€ë˜ë„ë¡ ê°€ì¤‘ì¹˜ ë¶„í¬ë¥¼ ì„¤ì •.<br>

ğŸ‘‰ kaiming_uniform_ì˜ bound ì™€ kaiming_normal_ì˜ std ëŠ”
ë ˆì´ì–´ì˜ fan ê°’ê³¼ í™œì„±í•¨ìˆ˜ì— ë§ì¶˜ ê°€ì¤‘ì¹˜ ë¶„í¬ì˜ ìŠ¤ì¼€ì¼ì¼ ë¿ì´ê³ ,
BatchNorm/LayerNormê³¼ëŠ” ë¬´ê´€í•´! (ì •ê·œí™” ë ˆì´ì–´ ì¢…ë¥˜ì™€ ìƒê´€ì—†ì´ â€œê°€ì¤‘ì¹˜ ì´ˆê¸° ë¶„í¬â€ë¥¼ ì •í•˜ëŠ” íŒŒë¼ë¯¸í„°ì•¼.)

## ğŸ§® fan_in / fan_out ì´ë€?

| ìš©ì–´        | ì˜ë¯¸                           |
| --------- | ---------------------------- |
| `fan_in`  | ì…ë ¥ feature ìˆ˜ (ì…ë ¥ ì±„ë„ Ã— ì»¤ë„ í¬ê¸°) |
| `fan_out` | ì¶œë ¥ feature ìˆ˜ (ì¶œë ¥ ì±„ë„ Ã— ì»¤ë„ í¬ê¸°) |

- ì˜ˆ: Conv2d(64, 128, kernel_size=3)<br>
â†’ fan_in = 64Ã—3Ã—3, fan_out = 128Ã—3Ã—3

```py
import torch.nn as nn

class MyNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv = nn.Conv2d(3, 64, 3, padding=1)
        self.fc = nn.Linear(64*32*32, 10)
        self.init_weights()

    def init_weights(self):
        nn.init.kaiming_normal_(self.conv.weight, mode='fan_out', nonlinearity='relu')
        nn.init.constant_(self.conv.bias, 0)
        nn.init.xavier_uniform_(self.fc.weight, gain=nn.init.calculate_gain('relu'))
        nn.init.zeros_(self.fc.bias)
```

## ì •ë¦¬

| ì¹´í…Œê³ ë¦¬        | ëŒ€í‘œ í•¨ìˆ˜                                  | ì£¼ ìš©ë„              |
| ----------- | -------------------------------------- | ----------------- |
| **ìƒìˆ˜ ì´ˆê¸°í™”**  | `constant_`, `zeros_`, `ones_`         | bias ë˜ëŠ” ì‹¤í—˜ìš©       |
| **í™•ë¥ ì  ì´ˆê¸°í™”** | `uniform_`, `normal_`, `trunc_normal_` | ì„ì˜ ë¶„í¬ë¡œ ì´ˆê¸°í™”        |
| **ì„ í˜• ë³´ì¡´í˜•**  | `eye_`, `dirac_`                       | í•­ë“± ë˜ëŠ” ID ë§¤í•‘ ë³´ì¡´    |
| **ì •ê·œí™” ê³„ì—´**  | `xavier_*`, `kaiming_*`                | ëŒ€ë¶€ë¶„ì˜ CNN / MLP ê¸°ë³¸ |
| **íŠ¹ìˆ˜ ëª©ì **   | `orthogonal_`, `sparse_`               | ì§êµì„±, í¬ì†Œì„± ë¶€ì—¬       |
