---
# Header
title: "3ì¥. ë¶„ë¥˜"
excerpt: "3ì¥. ë¶„ë¥˜"
name: J
writer: J
categories: [ì±… ì •ë¦¬, í•¸ì¦ˆì˜¨ ë¨¸ì‹ ëŸ¬ë‹] # [ë©”ì¸ ì¹´í…Œê³ ë¦¬, ì„œë¸Œ ì¹´í…Œê³ ë¦¬]
tags:
  - []

toc: true
toc_sticky: true

date: 2025-02-09
last_modified_at: 2024-02-09

# --- ì•„ë˜ ë¶€í„° content
---

# 3.1 MNIST

â­ê¸°ë³¸ì ìœ¼ë¡œ ì‚¬ì´í‚·ëŸ°ì€ ë‚´ë ¤ë°›ì€ ë°ì´í„°ì…‹ì„ ì‚¬ìš©ì í™ˆ ë””ë ‰í„°ë¦¬ ì•ˆì˜ scikit_learn_data ë””ë ‰í„°ë¦¬ì— ìºì‹±í•œë‹¤.

ğŸ”–data ë‹¤ìš´ë¡œë“œ

```py
from sklearn.datasets import fetch_openml

# ì‚¬ì´í‚·ëŸ° 1.2ì—ì„œ ì¶”ê°€ëœ parser ë§¤ê°œë³€ìˆ˜ ê¸°ë³¸ê°’ì´ 1.4 ë²„ì „ì—ì„œ 'liac-arff'ì—ì„œ 'auto'ë¡œ ë°”ë€ë‹ˆë‹¤.
# 'auto'ì¼ ê²½ìš° í¬ì†Œí•œ ARFF í¬ë§·ì¼ ë•ŒëŠ” 'liac-arff', ê·¸ë ‡ì§€ ì•Šì„ ë•ŒëŠ” 'pandas'ê°€ ë©ë‹ˆë‹¤.
# ì´ì— ëŒ€í•œ ê²½ê³ ë¥¼ í”¼í•˜ë ¤ë©´ parser='auto'ë¡œ ì§€ì •í•˜ì„¸ìš”.
mnist = fetch_openml('mnist_784', as_frame=False)

mnist.keys() # Sklearn.utils.Bunch ê°ì²´ì¼ë•Œ ë­ ìˆë‚˜ í™•ì¸ ê°€ëŠ¥.
X, y = mnist.data, mnist.target
```

> ğŸ’¡Sklearn.datasets íŒ¨í‚¤ì§€ì— ìˆëŠ” í•¨ìˆ˜<br>
o fetch_* í•¨ìˆ˜: ì‹¤ì „ ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œ (ex. fetch_openml())<br>
o load_* í•¨ìˆ˜: ì‚¬ì´í‚·ëŸ°ì— ë²ˆë“¤ë¡œ í¬í•¨ëœ ì†Œê·œëª¨ ë°ì´í„°ì…‹ì„ ë¡œë“œí•˜ê¸° ìœ„í•œ í•¨ìˆ˜<br>
o make_* í•¨ìˆ˜: í…ŒìŠ¤íŠ¸ì— ìœ ìš©í•œ ê°€ì§œ ë°ì´í„°ì…‹ì„ ìƒì„±í•˜ê¸° ìœ„í•œ í•¨ìˆ˜<br><br>
=> ìƒì„±ëœ ë°ì´í„°ì…‹ì€ ì¼ë°˜ì ìœ¼ë¡œ ë„˜íŒŒì´ ë°°ì—´, ì…ë ¥ê³¼ íƒ€ê¹ƒ ë°ì´í„°ë¥¼ ë‹´ì€ (X, y) íŠœí”Œë¡œ ë°˜í™˜.<br>
=> sklearn.utils.Bunch ê°ì²´ë¡œ ë°˜í™˜ë  ìˆ˜ë„!

> ğŸ’¡Sklearn.utils.Bunch ê°ì²´<br>
ì´ ê°ì²´ëŠ” ì†ì„±ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì€ í•­ëª©ì„ ì°¸ì¡°í•  ìˆ˜ ìˆëŠ” ë”•ì…”ë„ˆë¦¬<br>
o DESCR: ë°ì´í„°ì…‹ ì„¤ëª…<br>
o data: ì…ë ¥ ë°ì´í„°, ì¼ë°˜ì ìœ¼ë¡œ 2D ë„˜íŒŒì´ ë°°ì—´<br>
o target: ë ˆì´ë¸”, ì¼ë°˜ì ìœ¼ë¡œ 1D ë„˜íŒŒì´ ë°°ì—´

> ğŸ’¡fetch_openml()<br>
o ê¸°ë³¸ì ìœ¼ë¡œ ì…ë ¥ì„ íŒë‹¤ìŠ¤ ë°ì´í„°í”„ë ˆì„, ë ˆì´ë¸”ì„ ì‹œë¦¬ì¦ˆë¡œ ë°˜í™˜.<br><br>
BUT! MNIST ë°ì´í„°ì…‹ì€ ì´ë¯¸ì§€ì„ë¡œ dfì´ ì˜ ë§ì§€ ì•Šë‹¤. ë”°ë¼ì„œ as_frame=Falseë¡œ ì§€ì •í•˜ì—¬ ë„˜íŒŒì´ ë°°ì—´ë¡œ ë°ì´í„°ë¥¼ ë°›ìŒ.

ğŸ”–ì´ë¯¸ì§€ ë³´ê¸°
```py
import matplotlib.pyplot as plt

def plot_digit(image_data):
    image = image_data.reshape(28, 28) # 2ì°¨ì›ìœ¼ë¡œ ë°”ê¾¸ê³ 
    plt.imshow(image, cmap="binary") # í‘ë°±ìœ¼ë¡œ ì¶œë ¥ë ¥
    plt.axis("off") # ì¶• ì•ˆë³´ì—¬ì£¼ê¸°!

some_digit = X[0] 
plot_digit(some_digit)
save_fig("some_digit_plot")  # ì¶”ê°€ ì½”ë“œ
plt.show()
```

ğŸ”–ìì„¸íˆ ë³´ê¸° ì „!!!! í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ë–¼ì–´ë†“ê¸°!!!!

```py
# MNISTëŠ” ì‚¬ì‹¤ ë¯¸ë¦¬ ë‚˜ëˆ„ì–´ì ¸ ìˆìŒã…

X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]
```

# 3.2 ì´ì§„ ë¶„ë¥˜ê¸° í›ˆë ¨

â—'5-ê°ì§€ê¸°'ëŠ” '5'ì™€ '5 ì•„ë‹˜' ë‘ ê°œì˜ í´ë˜ìŠ¤ë¥¼ êµ¬ë¶„í•  ìˆ˜ ìˆëŠ” **ì´ì§„ ë¶„ë¥˜ê¸°** ì´ë‹¤.


ğŸ”–íƒ€ê¹ƒ ë²¡í„° ë§Œë“¤ê¸°!
```py
y_train_5 = (y_train == '5')  # 5ëŠ” Trueê³ , ë‹¤ë¥¸ ìˆ«ìëŠ” ëª¨ë‘ False
y_test_5 = (y_test == '5')
```

ğŸ”–SGD(í™•ë¥ ì  ê²½ì‚¬ í•˜ê°•ë²•) í›ˆë ¨ ì‹œí‚¤ê¸°

> ğŸ’¡SGD ë¶„ë¥˜ê¸°?<br>
o í•œ ë²ˆì— í•˜ë‚˜ì”© í›ˆë ¨ ìƒ˜í”Œì„ ë…ë¦½ì ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆìŒ.(ì˜¨ë¼ì¸ í•™ìŠµì— ì˜ ë“¤ì–´ë§ìŒ)<br>
o ë§¤ìš° í° ë°ì´í„°ì…‹ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆìŒ.

```py
from sklearn.linear_model import SGDClassifier

sgd_clf = SGDClassifier(random_state=42)
sgd_clf.fit(X_train, y_train_5)
```

# 3.3 ì„±ëŠ¥ ì¸¡ì •

â— ë¶„ë¥˜ê¸° í‰ê°€ëŠ” íšŒê·€ ëª¨ë¸ë³´ë‹¤ í›¨ì”¬ ì–´ë ¤ì›€!

### 3.3.1 êµì°¨ ê²€ì¦ì„ ì‚¬ìš©í•œ ì •í™•ë„ ì¸¡ì •

ğŸ”–êµì°¨ ê²€ì¦ êµ¬í˜„

- ì‚¬ì´í‚·ëŸ°ì´ ì œê³µí•˜ëŠ” ê¸°ëŠ¥ë³´ë‹¤ êµì°¨ ê²€ì¦ ê³¼ì •ì„ ë” ë§ì´ ì œì–´í•´ì•¼ í•˜ë©´, ì§ì ‘ êµ¬í˜„í•´ë´ì•¼í•¨!!

```py
from sklearn.model_selection import StratifiedKFold
from sklearn.base import clone

skfolds = StratifiedKFold(n_splits=3)
# ë°ì´í„°ê°€ ë¯¸ë¦¬ ì„ì—¬ìˆì§€ ì•Šë‹¤ë©´, shuffle=True ì¶”ê°€
# StratifiedKFoldëŠ” í´ë˜ìŠ¤ë³„ ë¹„ìœ¨ì´ ìœ ì§€ë˜ë„ë¡ í´ë“œë¥¼ ë§Œë“¦.

for train_index, test_index in skfolds.split(X_train, y_train_5):
    clone_clf = clone(sgd_clf) # ëª¨ë¸ ë³µì‚¬
    X_train_folds = X_train[train_index]
    y_train_folds = y_train_5[train_index]
    X_test_fold = X_train[test_index]
    y_test_fold = y_train_5[test_index]

    clone_clf.fit(X_train_folds, y_train_folds)
    y_pred = clone_clf.predict(X_test_fold)
    n_correct = sum(y_pred==y_test_fold)
    print(n_correct / len(y_pred))
```

ğŸ”–êµì°¨ ê²€ì¦ ìˆ˜í–‰

```py
from sklearn.model_selection import cross_val_score

cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring="accuracy")
# array([0.95035, 0.96035, 0.9604 ])
```

ëª¨ë“  ì´ë¯¸ì§€ë¥¼ ê°€ì¥ ë§ì´ ë“±ì¥í•˜ëŠ” í´ë˜ìŠ¤(ì—¬ê¸°ì„œëŠ” ìŒì„± í´ë˜ìŠ¤, ì¦‰ '5 ì•„ë‹˜')ë¡œ ë¶„ë¥˜í•˜ëŠ” ë”ë¯¸ ë¶„ë¥˜ê¸°ë¥¼ ë§Œë“¤ì–´ ë¹„êµ!!

```py
from sklearn.dummy import DummyClassifier

dummy_clf = DummyClassifier()
dummy_clf.fit(X_train, y_train_5)
print(any(dummy_clf.predict(X_train)))

cross_val_score(dummy_clf, X_train, y_train_5, cv=3, scoring="accuracy")
# array([0.90965, 0.90965, 0.90965])
```

> ğŸ’¡ë”ë¯¸ ë¶„ë¥˜ê¸°ë€??<br>
o "ì‹¤ì œ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì´ ì•„ë‹ˆë¼, ë‹¨ìˆœí•œ ê¸°ì¤€(rule)ìœ¼ë¡œ ë¶„ë¥˜í•˜ëŠ” ë§¤ìš° ë‹¨ìˆœí•œ ëª¨ë¸!"
"ì‹¤ì œ ëª¨ë¸ê³¼ ë¹„êµí•˜ê¸° ìœ„í•´ ì‚¬ìš©ë¨!"


ğŸ’¬ íŠ¹íˆ, **ë¶ˆê· í˜•í•œ ë°ì´í„°ì…‹**ì„ ë‹¤ë£° ë•Œ, ì •í™•ë„ë¥¼ ë¶„ë¥˜ê¸°ì˜ ì„±ëŠ¥ ì¸¡ì • ì§€í‘œë¡œ ì„ í˜¸í•˜ì§€ ì•ŠìŒ. <br>
ğŸ’¬ ë¶„ë¥˜ê¸°ì˜ ì„±ëŠ¥ì„ í‰ê°€í• ë• **ì˜¤ì°¨ í–‰ë ¬**ì´ ë” ì¢‹ìŒ!!

### 3.2.2 ì˜¤ì°¨ í–‰ë ¬

â— í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ì˜ˆì¸¡ì„ ë§Œë“¤ ìˆ˜ ìˆì§€ë§Œ, ì—¬ê¸°ì„œ ì´ìš©í•˜ë©´ ì•ˆë¨!!!(í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ëŠ” í”„ë¡œì íŠ¸ì˜ ë§¨ ë§ˆì§€ë§‰ì— ë¶„ë¥˜ê¸°ê°€ ì¶œì‹œ ì¤€ë¹„ ë§ˆì¹˜ê³  ì´ìš©!!)

```py
from sklearn.model_selection import cross_val_predict

y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)
# í›ˆë ¨ ì„¸íŠ¸ì˜ ëª¨ë“  ìƒ˜í”Œì— ëŒ€í•´ ê¹¨ë—í•œ ì˜ˆì¸¡ì„ ì–»ê²Œ ë¨.

from sklearn.metrics import confusion_matrix

cm = confusion_matrix(y_train_5, y_train_pred)
cm
# array([[53892,   687],
#      [ 1891,  3530]])
```

- í–‰: **ì‹¤ì œ í´ë˜ìŠ¤** / ì—´: **ì˜ˆì¸¡í•œ í´ë˜ìŠ¤**  
    - ì²« ë²ˆì§¸ í–‰: **ìŒì„± í´ë˜ìŠ¤** 
        - ì§„ì§œ ìŒì„±(ì²« ë²ˆì§¸ í–‰ì˜ ì²« ë²ˆì§¸ ì—´)
        - ê±°ì§“ ì–‘ì„± or 1ì¢… ì˜¤ë¥˜(ì²« ë²ˆì§¸ í–‰ì˜ ë‘ ë²ˆì§¸ ì—´)
    - ë‘ ë²ˆì§¸ í–‰: **ì–‘ì„± í´ë˜ìŠ¤**
        - ê±°ì§“ ìŒì„± or 2ì¢… ì˜¤ë¥˜(ë‘ ë²ˆì§¸ í–‰ì˜ ì²« ë²ˆì§¸ ì—´)
        - ì§„ì§œ ì–‘ì„±(ë‘ ë²ˆì§¸ í–‰ì˜ ë‘ ë²ˆì§¸ ì—´)

```py
y_train_perfect_predictions = y_train_5  # ì™„ë²½í•œ ë¶„ë¥˜ê¸°ì¼ ê²½ìš°
confusion_matrix(y_train_5, y_train_perfect_predictions)
#array([[54579,     0],
#       [    0,  5421]], dtype=int64)
# ì™„ë²½í•˜ë©´ ì£¼ëŒ€ê°ì„ ë§Œ 0ì´ ì•„ë‹Œ ê°’ì´ ëœë‹¤.
```

ğŸ”–ì˜¤ì°¨ í–‰ë ¬ì˜ ì§€í‘œ

1. ì •ë°€ë„(ì–‘ì„± ì˜ˆì¸¡ì˜ ì •í™•ë„)
    - TP / (FP + TP)
    - ì˜¬ë¦¬ëŠ” ê°€ì¥ ì‰¬ìš´ ë°©ë²•: ì œì¼ í™•ì‹ ì´ ë†’ì€ ìƒ˜í”Œì— ëŒ€í•´ ì–‘ì„± ì˜ˆì¸¡ì„ í•˜ê³  ë‚˜ë¨¸ì§€ëŠ” ëª¨ë‘ ìŒì„± ì˜ˆì¸¡ì„ í•˜ëŠ” ë¶„ë¥˜ê¸°

2. ì¬í˜„ìœ¨(ë¯¼ê°ë„ or ì§„ì§œ ì–‘ì„± ë¹„ìœ¨)
    - TP / (TP + FN)

    ![alt text](/assets/img_20250311/image-1.png)

### 3.3.3 ì •ë°€ë„ì™€ ì¬í˜„ìœ¨

ğŸ”–F1 ì ìˆ˜

- ì •ë°€ë„ì™€ ì¬í˜„ìœ¨ì˜ ì¡°í™” í‰ê· (ë³´í†µì˜ í‰ê· ì€ ëª¨ë“  ê°’ì„ ë™ì¼í•˜ê²Œ ì·¨ê¸‰í•˜ì§€ë§Œ, ì¡°í™” í‰ê· ì€ ë‚®ì€ ê°’ì— í›¨ì”¬ ë†’ì€ ë¹„ì¤‘ì„ ë‘ ).

![alt text](/assets/img_20250311/image-2.png)

```py
from sklearn.metrics import f1_score

f1_score(y_train_5, y_train_pred)
```

â—ì •ë°€ë„ì™€ ì¬í˜„ìœ¨ì´ ë¹„ìŠ·í•œ ë¶„ë¥˜ê¸°(F1 ì ìˆ˜ ë†’ìŒ)ê°€ í•­ìƒ ë°”ëŒì§í•œ ê²ƒì€ ì•„ë‹ˆë‹¤. ìƒí™©ì— ë”°ë¼ ì •ë°€ë„ê°€ ì¤‘ìš”í•  ìˆ˜ë„ ìˆê³ , ì¬í˜„ìœ¨ì´ ì¤‘ìš”í•  ìˆ˜ë„ ìˆë‹¤.<br>
â— **ì •ë°€ë„/ì¬í˜„ìœ¨ íŠ¸ë ˆì´ë“œì˜¤í”„**

### 3.3.4 ì •ë°€ë„/ì¬í˜„ìœ¨ íŠ¸ë ˆì´ë“œ ì˜¤í”„

â—ì„ê³„ê°’ì´ ë†’ì„ ìˆ˜ë¡, ì¬í˜„ìœ¨ì€ ë‚®ì•„ì§€ê³  ë°˜ëŒ€ë¡œ ì •ë°€ë„ëŠ” ë†’ì•„ì§„ë‹¤.

- decision_function() ë©”ì„œë“œ: ê° ìƒ˜í”Œì˜ ì ìˆ˜ë¥¼ ì–»ì„ ìˆ˜ ìˆìŒ.

```py
y_scores = sgd_clf.decision_function([some_digit])
y_scores
threshold = 0
y_some_digit_pred = (y_scores > threshold)
y_some_digit_pred
# True

threshold = 3000
y_some_digit_pred = (y_scores > threshold)
y_some_digit_pred
# False
```

ğŸ”– ì ì ˆí•œ ì„ê³„ê°’ êµ¬í•˜ê¸°!

- cross_val_predict(): í›ˆë ¨ ì„¸íŠ¸ì— ìˆëŠ” ëª¨ë“  ìƒ˜í”Œì˜ ì ìˆ˜ êµ¬í•˜ê¸°.

- precision_recall_curve(): ê°€ëŠ¥í•œ ëª¨ë“  ì„ê³—ê°’ì— ëŒ€í•´ ì •ë°€ë„ì™€ ì¬í˜„ìœ¨ êµ¬í•¨(ì´ í•¨ìˆ˜ëŠ” ë¬´í•œí•œ ì„ê³—ê°’ì— í•´ë‹¹í•˜ëŠ” ê°’ìœ¼ë¡œ ë§ˆì§€ë§‰ ì •ë°€ë„ì— 1ì„, ë§ˆì§€ë§‰ ì¬í˜„ìœ¨ì— 0ì„ ì¶”ê°€í•œë‹¤.)

```py
y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3, method="decision_function")
# ì´ë²ˆì—” ì˜ˆì¸¡ì´ ì•„ë‹Œ ê²°ì • ì ìˆ˜ ë°˜í™˜

from sklearn.metrics import precision_recall_curve

precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)


plt.figure(figsize=(8, 4))  # ì¶”ê°€ ì½”ë“œ
plt.plot(thresholds, precisions[:-1], "b--", label="Precision", linewidth=2)
plt.plot(thresholds, recalls[:-1], "g-", label="Recall", linewidth=2)
plt.vlines(threshold, 0, 1.0, "k", "dotted", label="threshold")

# ì¶”ê°€ ì½”ë“œ â€“ ê·¸ë¦¼ 3â€“5ë¥¼ ê·¸ë¦¬ê³  ì €ì¥í•©ë‹ˆë‹¤
idx = (thresholds >= threshold).argmax()  # ì²« ë²ˆì§¸ index â‰¥ threshold
plt.plot(thresholds[idx], precisions[idx], "bo")
plt.plot(thresholds[idx], recalls[idx], "go")
plt.axis([-50000, 50000, 0, 1])
plt.grid()
plt.xlabel("Threshold")
plt.legend(loc="center right")
save_fig("precision_recall_vs_threshold_plot")

plt.show()
```
![alt text](/assets/img_20250311/image-3.png)

â­ì„ê³„ê°’ì´ ì˜¬ë¼ê°€ë©´, ì¬í˜„ìœ¨ì€ ë‚®ì•„ì§ˆ ìˆ˜ë°–ì— ì—†ê³  ì •ë°€ë„ëŠ” ì˜¬ë¼ê°ˆ ìˆ˜ë„? ë‚´ë ¤ê°ˆ ìˆ˜ë„ ìˆë‹¤.

```py
import matplotlib.patches as patches  # ì¶”ê°€ ì½”ë“œ â€“ êµ¬ë¶€ëŸ¬ì§„ í™”ì‚´í‘œë¥¼ ê·¸ë¦¬ê¸° ìœ„í•´ì„œ

plt.figure(figsize=(6, 5))  # ì¶”ê°€ ì½”ë“œ

plt.plot(recalls, precisions, linewidth=2, label="Precision/Recall curve")

# extra code â€“ just beautifies and saves Figure 3â€“6
plt.plot([recalls[idx], recalls[idx]], [0., precisions[idx]], "k:")
plt.plot([0.0, recalls[idx]], [precisions[idx], precisions[idx]], "k:")
plt.plot([recalls[idx]], [precisions[idx]], "ko",
         label="Point at threshold 3,000")
plt.gca().add_patch(patches.FancyArrowPatch(
    (0.79, 0.60), (0.61, 0.78),
    connectionstyle="arc3,rad=.2",
    arrowstyle="Simple, tail_width=1.5, head_width=8, head_length=10",
    color="#444444"))
plt.text(0.56, 0.62, "Higher\nthreshold", color="#333333")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.axis([0, 1, 0, 1])
plt.grid()
plt.legend(loc="lower left")
save_fig("precision_vs_recall_plot")

plt.show()
```
![alt text](/assets/img_20250311/image-4.png)

â­ì •ë°€ë„ì˜ ê¸‰ í•˜ê°•ì  ì§ì „ì„ ì •ë°€ë„/ì¬í˜„ìœ¨ íŠ¸ë ˆì´ë“œì˜¤í”„ë¡œ ì„ íƒí•˜ëŠ” ê²ƒì´ ì¢‹ìŒ.

```py
idx_for_90_precision = (precisions >= 0.90).argmax()
threshold_for_90_precision = thresholds[idx_for_90_precision]
threshold_for_90_precision
# 3370.0194991439557
```

### 3.3.5 ROC ê³¡ì„ 

ğŸ”–ROC ê³¡ì„ ì´ë€?

- ê±°ì§“ ì–‘ì„± ë¹„ìœ¨(FPR)ì— ëŒ€í•œ ì§„ì§œ ì–‘ì„± ë¹„ìœ¨(TPR - ì¬í˜„ìœ¨)
- ì¬í˜„ìœ¨(ë¯¼ê°ë„)ì— ëŒ€í•œ 1-íŠ¹ì´ë„(íŠ¹ì´ë„ - TNR) ê·¸ë˜í”„

ğŸ”–ROC ê³¡ì„  ê·¸ë¦¬ê¸°

```py
from sklearn.metrics import roc_curve

fpr, tpr, thresholds = roc_curve(y_train_5, y_scores)

idx_for_threshold_at_90 = (thresholds <= threshold_for_90_precision).argmax()
# ì„ê³„ê°’ì´ ë‚´ë¦¼ìœ¼ë¡œ ë˜ì–´ìˆê¸°ì—...

tpr_90, fpr_90 = tpr[idx_for_threshold_at_90], fpr[idx_for_threshold_at_90]

plt.figure(figsize=(6, 5))  # ì¶”ê°€ ì½”ë“œ
plt.plot(fpr, tpr, linewidth=2, label="ROC curve")
plt.plot([0, 1], [0, 1], 'k:', label="Random classifier's ROC curve")
plt.plot([fpr_90], [tpr_90], "ko", label="Threshold for 90% precision")

# ì¶”ê°€ ì½”ë“œ â€“ ê·¸ë¦¼ 3â€“7ì„ ê·¸ë¦¬ê³  ì €ì¥í•©ë‹ˆë‹¤
plt.gca().add_patch(patches.FancyArrowPatch(
    (0.20, 0.89), (0.07, 0.70),
    connectionstyle="arc3,rad=.4",
    arrowstyle="Simple, tail_width=1.5, head_width=8, head_length=10",
    color="#444444"))
plt.text(0.12, 0.71, "Higher\nthreshold", color="#333333")
plt.xlabel('False Positive Rate (Fall-Out)')
plt.ylabel('True Positive Rate (Recall)')
plt.grid()
plt.axis([0, 1, 0, 1])
plt.legend(loc="lower right", fontsize=13)
save_fig("roc_curve_plot")

plt.show()
```
![alt text](/assets/img_20250311/image-5.png)

ğŸ”– AUC

- AUC(ê³¡ì„  ì•„ë˜ì˜ ë©´ì )
    - ì™„ë²½í•œ ë¶„ë¥˜ê¸°ëŠ” ROCì˜ AUCê°€ 1ì´ê³ , ì™„ì „í•œ ëœë¤ ë¶„ë¥˜ê¸°ëŠ” 0.5 ì…ë‹ˆë‹¤.

```py
from sklearn.metrics import roc_auc_score

roc_auc_score(y_train_5, y_scores)
# 0.96
```

> ğŸ’¡ROC? ì •ë°€ë„/ì¬í˜„ìœ¨ ê³¡ì„ ?<br>
o ì–‘ì„± í´ë˜ìŠ¤ê°€ ë“œë¬¼ê±°ë‚˜ ê±°ì§“ ìŒì„±ë³´ë‹¤ ê±°ì§“ ì–‘ì„±ì´ ë” ì¤‘ìš”í•  ë•Œ PR(ì •ë°€ë„/ì¬í˜„ìœ¨ ê³¡ì„ ) <-> ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ROC!

ğŸ”–RandomForestClassifierì™€ SGDClassifierì˜ PRê³¡ì„ ê³¼ F1 ë¹„êµ

```py
from sklearn.ensemble import RandomForestClassifier

forest_clf = RandomForestClassifier(random_state=42)
```

- predict_proba(): ê° ìƒ˜í”Œì— ëŒ€í•œ í´ë˜ìŠ¤ í™•ë¥ (ì‘ë™ ë°©ì‹ ë•Œë¬¸ì— decision_function() ì œê³µ X)
    - ì–‘ì„± í´ë˜ìŠ¤ì— ëŒ€í•œ ì ìˆ˜ ì´ìš©

```py
y_probas_forest = cross_val_predict(forest_clf, X_train, y_train_5, cv=3,method="predict_proba")
```

> ğŸ’¡ì¶”ì •í™•ë¥  <br>
o ì´ëŠ” ì‹¤ì œ í™•ë¥ X ì¶”ì • í™•ë¥ !<br>
o sklearn.calibration íŒ¨í‚¤ì§€ì—ëŠ” ì¶”ì • í™•ë¥ ì„ ë³´ì •í•˜ì—¬ ì‹¤ì œ í™•ë¥ ì— í›¨ì”¬ ê°€ê¹ê²Œ ë§Œë“œëŠ” ë„êµ¬ ìˆìŒ.

```py
y_scores_forest = y_probas_forest[:, 1]
precisions_forest, recalls_forest, thresholds_forest = precision_recall_curve(
    y_train_5, y_scores_forest)

plt.figure(figsize=(6, 5))  # ì¶”ê°€ ì½”ë“œ

plt.plot(recalls_forest, precisions_forest, "b-", linewidth=2,
         label="Random Forest")
plt.plot(recalls, precisions, "--", linewidth=2, label="SGD")

# ì¶”ê°€ ì½”ë“œ â€“ ê·¸ë¦¼ 3â€“8ì„ ê·¸ë¦¬ê³  ì €ì¥í•©ë‹ˆë‹¤
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.axis([0, 1, 0, 1])
plt.grid()
plt.legend(loc="lower left")
save_fig("pr_curve_comparison_plot")

plt.show()
```
![alt text](/assets/img_20250311/image-6.png)

# 3.4 ë‹¤ì¤‘ ë¶„ë¥˜

- ë‹¤ì¤‘ ë¶„ë¥˜ê¸°(ë‹¤í•­ ë¶„ë¥˜ê¸°): ë‘˜ ì´ìƒì˜ í´ë˜ìŠ¤ë¥¼ ë¹„êµí•  ìˆ˜ ìˆìŒ.
    - LogisticRegression, RandomForestClassifier, GaussianNB ë“±ì€ ê°€ëŠ¥!
    - SGDClassifierì™€ SVCì™€ ê°™ì€ ë‹¤ë¥¸ ì•Œê³ ë¦¬ì¦˜ì€ ì´ì§„ ë¶„ë¥˜ë§Œ ê°€ëŠ¥.
        - **BUT!!** ì´ì§„ ë¶„ë¥˜ê¸°ë¥¼ ì—¬ëŸ¬ ê°œ ì‚¬ìš©í•´ ë‹¤ì¤‘ í´ë˜ìŠ¤ë¥¼ ë¶„ë¥˜í•˜ëŠ” ê¸°ë²•ë„ ë§ë‹¤.
            - OvR or Ova: ê° í´ë˜ìŠ¤ë§ˆë‹¤ ì´ì§„ ë¶„ë¥˜ë¥¼ í›ˆë ¨ì‹œí‚¨ë’¤, ì´ë¯¸ì§€ë¥¼ ë¶„ë¥˜í•  ë•Œ ê° ë¶„ë¥˜ê¸°ì˜ ê²°ì • ì ìˆ˜ ì¤‘ì—ì„œ ê°€ì¥ ë†’ì€ ê²ƒì„ í´ë˜ìŠ¤ë¡œ!
            - OvO: 0ê³¼ 1 êµ¬ë³„, 0ê³¼ 2 êµ¬ë³„ ë“±ê³¼ ê°™ì´ ê° ìˆ«ìì˜ ì¡°í•©ë§ˆë‹¤ ì´ì§„ ë¶„ë¥˜ê¸°ë¥¼ í›ˆë ¨ì‹œí‚¤ëŠ” ê²ƒ! í´ë˜ìŠ¤ê°€ Nê°œë¼ë©´ ë¶„ë¥˜ê¸°ëŠ” N x (N-1) / 2ê°œê°€ í•„ìš”!

ğŸ”–ì„œí¬íŠ¸ ë²¡í„° ë¨¸ì‹  ë¶„ë¥˜ê¸°

```py
from sklearn.svm import SVC

svm_clf = SVC(random_state=42)
svm_clf.fit(X_train[:2000], y_train[:2000])  # y_train_5ê°€ ì•„ë‹ˆê³  y_trainì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
```

ì´ë•Œ, ì‚¬ì´í‚·ëŸ°ì€ OvO ì „ëµì„ ì´ìš©í•´ 45ê°œì˜ ì´ì§„ ë¶„ë¥˜ê¸°ë¥¼ í›ˆë ¨!

```py
svm_clf.predict([some_digit])
```
```py
some_digit_scores = svm_clf.decision_function([some_digit])
some_digit_scores.round(2)
# array([[ 3.79,  0.73,  6.06,  8.3 , -0.29,  9.3 ,  1.75,  2.77,  7.21, 4.82]])
```

ì´ë•Œ, ê° í´ë˜ìŠ¤ëŠ” ë™ë¥  ë¬¸ì œë¥¼ í•´ê²° í•˜ê¸° ìœ„í•´ ë¶„ë¥˜ê¸° ì ìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê° ìŒì—ì„œ ì´ê¸´ íšŸìˆ˜ì— ì•½ê°„ì˜ ì¡°ì • ê°’(ìµœëŒ€ +-0.33)ì„ ë”í•˜ê±°ë‚˜ ëº€ ì ìˆ˜ë¥¼ ì–»ëŠ”ë‹¤.

```py
class_id = some_digit_scores.argmax()
class_id

svm_clf.classes_
# array(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'], dtype=object)

svm_clf.classes_[class_id]

# ì¶”ê°€ ì½”ë“œ â€“ 45ê°œ OvO ì ìˆ˜ë¥¼ ì–»ëŠ” ë°©ë²•
svm_clf.decision_function_shape = "ovo"
some_digit_scores_ovo = svm_clf.decision_function([some_digit])
some_digit_scores_ovo.round(2)
```
â— ê·¼ë° ì´ë ‡ê²Œ ì¸ë±ìŠ¤ ê°’ê³¼ ê°’ì´ ê°™ì€ ê²½ìš°ëŠ” ë“œë¬¼ë‹¤!

ğŸ”–OneVsOneClassifierë‚˜ OneVsRestClassifier

- ì´ì§„ ë¶„ë¥˜ê¸° ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë§Œë“¤ì–´ ê°ì²´ë¥¼ ìƒì„±í•  ë•Œ ì „ë‹¬í•˜ë©´ ë©ë‹ˆë‹¤(ì´ì§„ ë¶„ë¥˜ê¸°ì¼ í•„ìš”X)

```py
from sklearn.multiclass import OneVsRestClassifier

ovr_clf = OneVsRestClassifier(SVC(random_state=42))
ovr_clf.fit(X_train[:2000], y_train[:2000])

ovr_clf.predict([some_digit])
# 5

len(ovr_clf.estimators_)
# 10
# ì¶”ì •ê¸° ê°¯ìˆ˜
```

ğŸ”–ë‹¤ì¤‘ ë¶„ë¥˜ datasetì— SGDClassifier í›ˆë ¨í•˜ê¸°

```py
sgd_clf = SGDClassifier(random_state=42)
sgd_clf.fit(X_train, y_train)
sgd_clf.predict([some_digit])
# 3

sgd_clf.decision_function([some_digit]).round()
# array([[-31893., -34420.,  -9531.,   1824., -22320.,  -1386., -26189., -16148.,  -4604., -12051.]])
```

```py
# í‰ê°€í•˜ê¸°
cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring="accuracy")
#array([0.87365, 0.85835, 0.8689 ])
```

ë‚˜ì˜ì§„ ì•Šì§€ë§Œ! ì…ë ¥ ìŠ¤ì¼€ì¼ì„ ì¡°ì •í•´ë³´ì!
```py
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train.astype("float64"))
cross_val_score(sgd_clf, X_train_scaled, y_train, cv=3, scoring="accuracy")
# array([0.8983, 0.891 , 0.9018])
```

# 3.5 ì˜¤ë¥˜ ë¶„ì„

ğŸ”–ì˜¤ì°¨ í–‰ë ¬ ì‚´í´ë³´ê¸°

```py
from sklearn.metrics import ConfusionMatrixDisplay

y_train_pred = cross_val_predict(sgd_clf, X_train_scaled, y_train, cv=3)
plt.rc('font', size=9)  # ì¶”ê°€ ì½”ë“œ - í°íŠ¸ í¬ê¸°ë¥¼ ì¤„ì…ë‹ˆë‹¤
ConfusionMatrixDisplay.from_predictions(y_train, y_train_pred)
plt.show()
```
![alt text](/assets/img_20250311/image-7.png)

ì—¬ê¸°ì„œ 5ë²ˆ í–‰ê³¼ 5ë²ˆ ì—´ì˜ ëŒ€ê°ì„ ì— ìˆëŠ” ì…€ì€ ë‹¤ë¥¸ ìˆ«ìë³´ë‹¤ ì•½ê°„ ë” ì–´ë‘¡ê²Œ ë³´ì„. ì´ëŠ” **ëª¨ë¸ì´ 5ì—ì„œ ë” ë§ì€ ì˜¤ë¥˜ë¥¼ ë²”í–ˆ**ê±°ë‚˜ **ë‹¤ë¥¸ ìˆ«ìë³´ë‹¤ 5ê°€ ì ê¸° ë•Œë¬¸**ì´ë‹¤. <br>
=> ê° ê°’ì„ í•´ë‹¹ í´ë˜ìŠ¤(True ë ˆì´ë¸”)ì˜ ì´ ì´ë¯¸ì§€ ìˆ˜ë¡œ ë‚˜ëˆ„ì–´ ì •ê·œí™”!!

```py
plt.rc('font', size=10)  # ì¶”ê°€ ì½”ë“œ
ConfusionMatrixDisplay.from_predictions(y_train, y_train_pred,
                                        normalize="true", values_format=".0%")
plt.show()
```
![alt text](/assets/img_20250311/image-8.png)

ì˜¤ë¥˜ë¥¼ ë” ëˆˆì— ë„ê²Œ ë§Œë“¤ê³  ì‹¶ë‹¤ë©´ ì˜¬ë°”ë¥¸ ì˜ˆì¸¡ì— ëŒ€í•œ ê°€ì¤‘ì¹˜ë¥¼ 0ìœ¼ë¡œ ì„¤ì •!

```py
sample_weight = (y_train_pred != y_train)
plt.rc('font', size=10)  # ì¶”ê°€ ì½”ë“œ
ConfusionMatrixDisplay.from_predictions(y_train, y_train_pred,
                                        sample_weight=sample_weight,
                                        normalize="true", values_format=".0%")
plt.show()
```
![alt text](/assets/img_20250311/image-9.png)

í–‰ ë‹¨ìœ„ê°€ ì•„ë‹Œ ì—´ ë‹¨ìœ„ë¡œ ì •ê·œí™” í•´ë³´ì!

```py
# ì¶”ê°€ ì½”ë“œ â€“ ê·¸ë¦¼ 3â€“10ì„ ìƒì„±í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤
fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(9, 4))
plt.rc('font', size=10)

ConfusionMatrixDisplay.from_predictions(y_train, y_train_pred, ax=axs[0],sample_weight=sample_weight
normalize="true", values_format=".0%")
axs[0].set_title("Errors normalized by row")

ConfusionMatrixDisplay.from_predictions(y_train, y_train_pred, ax=axs[1],sample_weight=sample_weight,
normalize="pred", values_format=".0%")
axs[1].set_title("Errors normalized by column")

save_fig("confusion_matrix_plot_2")
plt.show()
plt.rc('font', size=14)  # í°íŠ¸ í¬ê¸°ë¥¼ ë‹¤ì‹œ í‚¤ì›ë‹ˆë‹¤
```
![alt text](/assets/img_20250311/image-10.png)

ê°ê°ì˜ ì˜¤ë¥˜ë¥¼ ë¶„ì„í•´ë³´ë©´ ë¶„ë¥˜ê¸°ê°€ ë¬´ìŠ¨ ì¼ì„ í•˜ëŠ”ì§€, ì™œ ì˜ëª»ë˜ì—ˆëŠ”ì§€ ì¸ì‚¬ì´íŠ¸ë¥¼ ì–»ì„ ìˆ˜ ìˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ì˜¤ì°¨ í–‰ë ¬ ìŠ¤íƒ€ì¼ë¡œ 3ê³¼ 5ì˜ ìƒ˜í”Œì„ ê·¸ë ¤ë³´ì!

```py
cl_a, cl_b = '3', '5'
X_aa = X_train[(y_train == cl_a) & (y_train_pred == cl_a)]
X_ab = X_train[(y_train == cl_a) & (y_train_pred == cl_b)]
X_ba = X_train[(y_train == cl_b) & (y_train_pred == cl_a)]
X_bb = X_train[(y_train == cl_b) & (y_train_pred == cl_b)]

# ì¶”ê°€ ì½”ë“œ â€“ ê·¸ë¦¼ 3â€“11ì„ ìƒì„±í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤
size = 5
pad = 0.2
plt.figure(figsize=(size, size))
for images, (label_col, label_row) in [(X_ba, (0, 0)), (X_bb, (1, 0)),
                                       (X_aa, (0, 1)), (X_ab, (1, 1))]:
    for idx, image_data in enumerate(images[:size*size]):
        x = idx % size + label_col * (size + pad)
        y = idx // size + label_row * (size + pad)
        plt.imshow(image_data.reshape(28, 28), cmap="binary",
                   extent=(x, x + 1, y, y + 1))
plt.xticks([size / 2, size + pad + size / 2], [str(cl_a), str(cl_b)])
plt.yticks([size / 2, size + pad + size / 2], [str(cl_b), str(cl_a)])
plt.plot([size + pad / 2, size + pad / 2], [0, 2 * size + pad], "k:")
plt.plot([0, 2 * size + pad], [size + pad / 2, size + pad / 2], "k:")
plt.axis([0, 2 * size + pad, 0, 2 * size + pad])
plt.xlabel("Predicted label")
plt.ylabel("True label")
save_fig("error_analysis_digits_plot")
plt.show()
```
![alt text](/assets/img_20250311/image-11.png)

â­ì„ í˜• ë¶„ë¥˜ê¸°ëŠ” í´ë˜ìŠ¤ë§ˆë‹¤ í”½ì…€ì— ê°€ì¤‘ì¹˜ë¥¼ í• ë‹¹í•˜ê³  ìƒˆë¡œìš´ ì´ë¯¸ì§€ì— ëŒ€í•´ ë‹¨ìˆœíˆ í”½ì„¼ ê°•ë„ì˜ ê°€ì¤‘ì¹˜ í•©ì„ í´ë˜ìŠ¤ì˜ ì ìˆ˜ë¡œ ê³„ì‚°!<br>
â­ëª¨ë¸ì´ ë³€í˜•ì— ë” ì˜ ê²¬ë””ë„ë¡ **ë°ì´í„° ì¦ì‹**ì´ìš©!

# 3.6 ë‹¤ì¤‘ ë ˆì´ë¸” ë¶„ë¥˜

ğŸ”–ë‹¤ì¤‘ ë ˆì´ë¸” ë¶„ë¥˜?
- ì—¬ëŸ¬ ê°œì˜ ì´ì§„ ê¼¬ë¦¬í‘œë¥¼ ì¶œë ¥í•˜ëŠ” ë¶„ë¥˜ ì‹œìŠ¤í…œ.

ğŸ”–KNeighborsClassifierë¥¼ ì´ìš©í•´ í•™ìŠµì‹œí‚¤ê¸°!

```py
import numpy as np
from sklearn.neighbors import KNeighborsClassifier

y_train_large = (y_train >= '7')
y_train_odd = (y_train.astype('int8') % 2 == 1)
y_multilabel = np.c_[y_train_large, y_train_odd]
# np.c_[] â†’ NumPyì—ì„œ ì—¬ëŸ¬ ê°œì˜ 1D ë°°ì—´ì„ ì—´(column) ê¸°ì¤€ìœ¼ë¡œ ë³‘í•©í•˜ëŠ” ê¸°ëŠ¥

knn_clf = KNeighborsClassifier()
knn_clf.fit(X_train, y_multilabel)
```

ğŸ”–F1 ì ìˆ˜ì˜ í‰ê·  ê³„ì‚°í•˜ê¸°!(í‰ê°€)

```py
y_train_knn_pred = cross_val_predict(knn_clf, X_train, y_multilabel, cv=3)
f1_score(y_multilabel, y_train_knn_pred, average="macro")
# 0.9764102655606048
```

í´ë˜ìŠ¤ê°€ ë¶ˆê· í˜•í•˜ë‹¤ë©´, ë ˆì´ë¸”ì— í´ë˜ìŠ¤ì˜ **ì§€ì§€ë„**(íƒ€ê¹ƒ ë ˆì´ë¸”ì— ì†í•œ ìƒ˜í”Œ ìˆ˜)ë¥¼ ê°€ì¤‘ì¹˜ë¡œ ì£¼ì!

```py
# ì¶”ê°€ ì½”ë“œ â€“ average="weighted"ë¡œ ì§€ì •í–ˆì„ ë•Œ ì„±ëŠ¥ í–¥ìƒì€ ë¬´ì‹œí•  ìˆ˜ ìˆëŠ” ìˆ˜ì¤€ì…ë‹ˆë‹¤.
#           ì´ í´ë˜ìŠ¤ëŠ” ì´ë¯¸ ê½¤ ê· í˜• ì¡í˜€ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.
f1_score(y_multilabel, y_train_knn_pred, average="weighted")
```

ğŸ”–ë‹¤ì¤‘ ë ˆì´ë¸” ë¶„ë¥˜ë¥¼ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¶„ë¥˜ê¸° ì‚¬ìš©?

- ë ˆì´ë¸”ë‹¹ í•˜ë‚˜ì˜ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ì!
- ë‹¨, ì´ ë°©ë²•ì€ ë ˆì´ë¸” ê°„ì˜ ì˜ì¡´ì„±ì„ í¬ì°©í•˜ê¸° ì–´ë µê²Œ í•  ìˆ˜ ìˆë‹¤.
=> í•´ê²° ìœ„í•´ ëª¨ë¸ì„ **ì²´ì¸**ìœ¼ë¡œ êµ¬ì„±í•  ìˆ˜ ìˆìŒ!<br>
=> ì‚¬ì´í‚·ëŸ°ì˜ **ClassifierChain**í´ë˜ìŠ¤ ì´ìš©!

> ğŸ’¡ClassifierChain<br>
o í›ˆë ¨ì—ëŠ” ì§„ì§œ ë ˆì´ë¸”ì„ ì´ìš©<br>
o ë‹¨, cv í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì§€ì •í•˜ë©´ êµì°¨ ê²€ì¦ì„ ì´ìš©í•˜ì—¬ í›ˆë ¨ ì„¸íŠ¸ì˜ ëª¨ë“  ìƒ˜í”Œì— ëŒ€í•´ í›ˆë ¨ëœ ê° ëª¨ë¸ì—ì„œ ê¹¨ë—í•œ ì—ì¸¡ì„ ì–»ê³ , ì´ëŸ¬í•œ ì˜ˆì¸¡ì„ ì´ìš©í•´ ë‚˜ì¤‘ì— ì²´ì¸ ì•ˆì˜ ëª¨ë“  ëª¨ë¸ì„ í›ˆë ¨.

```py
from sklearn.multioutput import ClassifierChain

chain_clf = ClassifierChain(SVC(), cv=3, random_state=42)
chain_clf.fit(X_train[:2000], y_multilabel[:2000])

chain_clf.predict([some_digit])
# array([[0., 1.]])
```

# 3.7 ë‹¤ì¤‘ ì¶œë ¥ ë¶„ë¥˜

ğŸ”–ë‹¤ì¤‘ ì¶œë ¥ ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜(ë‹¤ì¤‘ ì¶œë ¥ ë¶„ë¥˜)
- ë‹¤ì¤‘ ë ˆì´ë¸” ë¶„ë¥˜ì—ì„œ í•œ ë ˆì´ë¸”ì´ ë‹¤ì¤‘ í´ë˜ìŠ¤ê°€ ë  ìˆ˜ ìˆë„ë¡ ì¼ë°˜í™” í•œê²ƒ.(ê°’ì„ ë‘ ê°œ ì´ìƒ ê°€ì§ˆ ìˆ˜ O)

ğŸ”–ì´ë¯¸ì§€ì—ì„œ ì¡ìŒì„ ì œê±°í•˜ëŠ” ì‹œìŠ¤í…œ ë§Œë“¤ê¸°!

```py
np.random.seed(42)  # ë™ì¼í•˜ê²Œ ì¬í˜„ë˜ê²Œ í•˜ë ¤ê³  ì§€ì •í•©ë‹ˆë‹¤
noise = np.random.randint(0, 100, (len(X_train), 784))
X_train_mod = X_train + noise
noise = np.random.randint(0, 100, (len(X_test), 784))
X_test_mod = X_test + noise
y_train_mod = X_train
y_test_mod = X_test
```

```py
knn_clf = KNeighborsClassifier()
knn_clf.fit(X_train_mod, y_train_mod)
clean_digit = knn_clsf.predict([X_test_mod[0]])
plot_digit(clean_digit)
save_fig("cleaned_digit_example_plot")  # ì¶”ê°€ ì½”ë“œ â€“ ê·¸ë¦¼ 3â€“13ì„ ì €ì¥í•©ë‹ˆë‹¤
plt.show()
```
![alt text](/assets/img_20250311/image-12.png)