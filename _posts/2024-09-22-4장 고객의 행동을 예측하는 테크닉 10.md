---
# Header
title: "4.고객의 행동을 예측하는 테크닉 10"
excerpt: "고객의 행동을 예측하는 테크닉 10"
name: J
writer: J
categories: [데비&추천시스템, 파이썬 데이터분석 실무 테크닉 100] # [메인 카테고리, 서브 카테고리]
tags:
  - [Khuda, ML, data]

toc: true
toc_sticky: true

date: 2024-09-22
last_modified_at: 2024-09-22

# --- 아래 부터 content
---
🔖전제 조건

![alt text](/assets/img_20240924/image.png)

use_log.csv와 customer_join.csv만 사용합니다.

# 031.데이터를 읽어 들이고 확인하자

### 데이터 불러오기

```py
import pandas as pd
customer = pd.read_csv('customer_join.csv')
customer.isnull().sum()
```
![alt text](/assets/img_20240924/image-1.png)

```py
import pandas as pd
uselog = pd.read_csv('use_log.csv')
uselog.isnull().sum()
```
![alt text](/assets/img_20240924/image-2.png)

# 032.클러스터링으로 회원을 그룹화하자

비지도학습 **클러스터링**을 이용해서 이용 이력을 기준으로 그룹화해보자.

### 클러스터링용 데이터 추출

```py
#필요한 변수 추출
customer_clustering = customer[["mean", "median", "max", "min", "membership_period"]]
customer_clustering.head()
```
![alt text](/assets/img_20240924/image-3.png)

### 클러스터링

- K-means: 변수 간의 거리를 기반으로 그룹화

❗mean, median, max, min(월 이용횟수 -> 1~8)과 membership_period(최댓값이 47)는 데이터가 크게 다르다. 따라서 표준화를 해야한다.

```py
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
customer_clustering_sc = sc.fit_transform(customer_clustering)

kmeans = KMeans(n_clusters=4, random_state=0)
#random_state: 데이터를 몇번째 부터 섞을지?->0으로 하면 그냥 원래 데이터 순서대로 가는거고 100으로 하면 100번째 데이터부터 시작해서 섞이는 식
clusters = kmeans.fit(customer_clustering_sc)
customer_clustering["cluster"] = clusters.labels_
print(customer_clustering["cluster"].unique())
customer_clustering.head()
```
![alt text](/assets/img_20240924/image-4.png)

# 033.클러스터링 결과를 분석하자

### 그룹별 데이터 수

```py
customer_clustering.columns = ["월평균값", "월중앙값", "월최댓값", "월최솟값", "회원기간", "cluster"]
customer_clustering.groupby("cluster").count()
```
![alt text](/assets/img_20240924/image-5.png)

### 그룹별 평균

```py
customer_clustering.groupby("cluster").mean()
```
![alt text](/assets/img_20240924/image-6.png)

# 034.클러스터링 결과를 가시화하자

### 차원 축소를 이용한 가시화

- 차원 축소: 정보를 되도록 잃지 않게 하면서 새로운 축을 만드는 것.

```py
from sklearn.decomposition import PCA
X = customer_clustering_sc
pca = PCA(n_components=2)
pca.fit(X)
x_pca = pca.transform(X)
pca_df = pd.DataFrame(x_pca)
pca_df["cluster"] = customer_clustering["cluster"]

import matplotlib.pyplot as plt
%matplotlib inline
for i in customer_clustering["cluster"].unique():
    tmp = pca_df.loc[pca_df["cluster"]==i]
    plt.scatter(tmp[0], tmp[1])
```
![alt text](/assets/img_20240924/image-9.png)

# ➕2개의 축이 어떤 변수로 구성되어있을까?

❗chaptGPT에게 도움을 받음.

### 로딩스 구하기

PCA 모델을 fit한 후, 로딩스는 components_ 속성에 저장됩니다. 이 값은 주성분마다 원래 데이터셋의 각 변수에 대한 기여도를 나타냅니다. 즉, 로딩스 행렬에서 각 행은 하나의 주성분을 나타내고, 각 열은 원래 데이터의 피처(변수)를 나타냅니다.

```py
import pandas as pd

# PCA에 사용된 변수들만 선택해서 로딩스 생성
used_columns = customer_clustering.columns[:5]  # PCA에 사용된 5개의 열을 선택
loadings = pd.DataFrame(pca.components_, columns=used_columns)
print(loadings)
```
![alt text](/assets/img_20240924/image-8.png)

- 크기 (절대값): 주성분에서 중요한 역할을 하는 변수는 값의 **크기(절대값)**에 따라 결정됩니다. 양수든 음수든 값이 크면, 그 변수가 주성분에 큰 영향을 미친다고 해석할 수 있습니다.<br><br>
- 방향: 양수나 음수는 단순히 변수와 주성분 간의 방향성을 나타냅니다. 예를 들어, 두 변수 모두 첫 번째 주성분에서 절대값이 크지만, 한 변수는 양수, 다른 변수는 음수라면 이 두 변수는 서로 상반된 방향으로 주성분에 기여하고 있다는 의미입니다.

# 035.클러스터링 결과를 바탕으로 탈퇴 회원의 경향을 파악하자


### 그룹별 탈퇴/지속 회원 집계

탈퇴 회원을 특정하기 위해서 is_deleted 열을 customer_clustering에 추가해서 cluster 및 is_deleted별로 집계해 보겠습니다.

```py
customer_clustering = pd.concat([customer_clustering, customer], axis=1)
# index로 연결되어 있기 때문에 결합가능
customer_clustering.groupby(["cluster", "is_deleted"], 
as_index=False).count()[["cluster", "is_deleted", "customer_id"]]
# is deleted: 0(stay),1(탈퇴)
```
![alt text](/assets/img_20240924/image-10.png)

### 그룹/정기적 이용 플래그별 집계

```py
customer_clustering.groupby(["cluster", "routine_flg"],as_index=False).count()[["cluster", "routine_flg", "customer_id"]]
```
![alt text](/assets/img_20240924/image-11.png)

# 036.다음 달의 이용 횟수 예측을 위해 데이터를 준비하자

과거 6개월의 이용 데이터를 사용해 다음 달의 이용 횟수를 예측해보자(회귀분석)

### 데이터 수정

특정 고객의 특정 월별 데이터 필요!(6개월 데이터와 그 다음달 데이터인 정답 데이터 필요)

```py
uselog["usedate"] = pd.to_datetime(uselog["usedate"])
uselog["연월"] = uselog["usedate"].dt.strftime("%Y%m")
uselog_months = uselog.groupby(["연월", "customer_id"],as_index=False).count()
uselog_months.rename(columns={"log_id":"count"}, inplace=True)
del uselog_months["usedate"]
uselog_months.head()
```
![alt text](/assets/img_20240924/image-12.png)

그리고 이번 달부터 과거 5개월분의 이용 횟수와 다음 달의 이용 횟수를 저장(2018.10~2019.3)

```py
year_months = list(uselog_months["연월"].unique())
predict_data = pd.DataFrame()
for i in range(6, len(year_months)):
    # 201810~201903
    tmp = uselog_months.loc[uselog_months["연월"]==year_months[i]]
    tmp.rename(columns={"count":"count_pred"}, inplace=True)
    
    for j in range(1,7):
        tmp_before = uselog_months.loc[uselog_months["연월"]==year_months[i-j]]
        # 6개월 전까지
        del tmp_before["연월"]
        tmp_before.rename(columns={"count":"count_{}".format(j-1)}, inplace=True)
        tmp = pd.merge(tmp, tmp_before, on="customer_id", how="left")
    predict_data=pd.concat([predict_data, tmp], ignore_index=True)
predict_data.head()
```
![alt text](/assets/img_20240924/image-13.png)

❗NAN값은 가입 기간이 짧아서 데이터가 존재하지 않는 경우

```py
predict_data = predict_data.dropna()
predict_data = predict_data.reset_index(drop=True)
#재정렬
predict_data.head()
```
![alt text](/assets/img_20240924/image-14.png)

# 037.특징이 되는 변수를 추가하자

기본 데이터가 시계열 데이터이므로 회원 기간을 추가해보자

### 고객 데이터에 start_date 칼럼 결합

```py
predict_data = pd.merge(predict_data, customer[["customer_id", "start_date"]], on="customer_id", how="left")
predict_data.head()
```
![alt text](/assets/img_20240924/image-15.png)

### 회원 기간 추가

연월과 start_date의 차이를 이용해 회원 기간을 월 단위로 작성해 보자.

```py
predict_data["now_date"] = pd.to_datetime(predict_data["연월"], format="%Y%m")
predict_data["start_date"] = pd.to_datetime(predict_data["start_date"])
from dateutil.relativedelta import relativedelta
predict_data["period"] = None
for i in range(len(predict_data)):
    delta = relativedelta(predict_data["now_date"][i], predict_data["start_date"][i])
    predict_data["period"][i] = delta.years*12 + delta.months
predict_data.head()
```
![alt text](/assets/img_20240924/image-16.png)

# 038.다음 달 이용 횟수를 예측하는 모델을 구축하자

### 예측 모델 구축

```py
predict_data = predict_data.loc[predict_data["start_date"]>=pd.to_datetime("20180401")]
# 오래된 회원은 가입 시기 데이터가 존재하지 않거나 이용 횟수가 안정적일 가능성이 있기 때문에 오래된 회원은 빼고 모델 구축
from sklearn import linear_model
import sklearn.model_selection
model = linear_model.LinearRegression()
X = predict_data[["count_0", "count_1", "count_2", "count_3", "count_4", "count_5", "period"]]
y = predict_data["count_pred"]
X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X,y)
# 학습용 데이터 75%, 평가용 데이터 25%
model.fit(X_train, y_train)
```
![alt text](/assets/img_20240924/image-17.png)

### 회귀 모델의 정확도

```py
print(model.score(X_train, y_train))
# 0.6070880656984303
print(model.score(X_test, y_test))
# 0.6101178418242166
```

# 039.모델에 기여하는 변수를 확인하자

### 기여하는 변수

```py
coef = pd.DataFrame({"feature_names":X.columns, "coefficient":model.coef_})
coef
```
![alt text](/assets/img_20240924/image-18.png)

# 040.다음 달의 이용 횟수를 예측하자

### 예측

회원 두 명의 이용 데이터를 작성해 보자.
```py
x1 = [3,4,4,6,8,7,8]
x2 = [2,2,3,3,4,6,8]
x_pred = [x1, x2]

model.predict(x_pred)
# array([3.81182518, 1.97102059])

# 출력
uselog_months.to_csv("use_log_months.csv", index=False)
```
