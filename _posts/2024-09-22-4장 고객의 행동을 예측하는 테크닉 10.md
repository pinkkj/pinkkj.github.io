---
# Header
title: "4.ê³ ê°ì˜ í–‰ë™ì„ ì˜ˆì¸¡í•˜ëŠ” í…Œí¬ë‹‰ 10"
excerpt: "ê³ ê°ì˜ í–‰ë™ì„ ì˜ˆì¸¡í•˜ëŠ” í…Œí¬ë‹‰ 10"
name: J
writer: J
categories: [ë°ë¹„&ì¶”ì²œì‹œìŠ¤í…œ, íŒŒì´ì¬ ë°ì´í„°ë¶„ì„ ì‹¤ë¬´ í…Œí¬ë‹‰ 100] # [ë©”ì¸ ì¹´í…Œê³ ë¦¬, ì„œë¸Œ ì¹´í…Œê³ ë¦¬]
tags:
  - [Khuda, ML, data]

toc: true
toc_sticky: true

date: 2024-09-22
last_modified_at: 2024-09-22

# --- ì•„ë˜ ë¶€í„° content
---
ğŸ”–ì „ì œ ì¡°ê±´

![alt text](/assets/img_20240924/image.png)

use_log.csvì™€ customer_join.csvë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.

# 031.ë°ì´í„°ë¥¼ ì½ì–´ ë“¤ì´ê³  í™•ì¸í•˜ì

### ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°

```py
import pandas as pd
customer = pd.read_csv('customer_join.csv')
customer.isnull().sum()
```
![alt text](/assets/img_20240924/image-1.png)

```py
import pandas as pd
uselog = pd.read_csv('use_log.csv')
uselog.isnull().sum()
```
![alt text](/assets/img_20240924/image-2.png)

# 032.í´ëŸ¬ìŠ¤í„°ë§ìœ¼ë¡œ íšŒì›ì„ ê·¸ë£¹í™”í•˜ì

ë¹„ì§€ë„í•™ìŠµ **í´ëŸ¬ìŠ¤í„°ë§**ì„ ì´ìš©í•´ì„œ ì´ìš© ì´ë ¥ì„ ê¸°ì¤€ìœ¼ë¡œ ê·¸ë£¹í™”í•´ë³´ì.

### í´ëŸ¬ìŠ¤í„°ë§ìš© ë°ì´í„° ì¶”ì¶œ

```py
#í•„ìš”í•œ ë³€ìˆ˜ ì¶”ì¶œ
customer_clustering = customer[["mean", "median", "max", "min", "membership_period"]]
customer_clustering.head()
```
![alt text](/assets/img_20240924/image-3.png)

### í´ëŸ¬ìŠ¤í„°ë§

- K-means: ë³€ìˆ˜ ê°„ì˜ ê±°ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê·¸ë£¹í™”

â—mean, median, max, min(ì›” ì´ìš©íšŸìˆ˜ -> 1~8)ê³¼ membership_period(ìµœëŒ“ê°’ì´ 47)ëŠ” ë°ì´í„°ê°€ í¬ê²Œ ë‹¤ë¥´ë‹¤. ë”°ë¼ì„œ í‘œì¤€í™”ë¥¼ í•´ì•¼í•œë‹¤.

```py
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
customer_clustering_sc = sc.fit_transform(customer_clustering)

kmeans = KMeans(n_clusters=4, random_state=0)
#random_state: ë°ì´í„°ë¥¼ ëª‡ë²ˆì§¸ ë¶€í„° ì„ì„ì§€?->0ìœ¼ë¡œ í•˜ë©´ ê·¸ëƒ¥ ì›ë˜ ë°ì´í„° ìˆœì„œëŒ€ë¡œ ê°€ëŠ”ê±°ê³  100ìœ¼ë¡œ í•˜ë©´ 100ë²ˆì§¸ ë°ì´í„°ë¶€í„° ì‹œì‘í•´ì„œ ì„ì´ëŠ” ì‹
clusters = kmeans.fit(customer_clustering_sc)
customer_clustering["cluster"] = clusters.labels_
print(customer_clustering["cluster"].unique())
customer_clustering.head()
```
![alt text](/assets/img_20240924/image-4.png)

# 033.í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì

### ê·¸ë£¹ë³„ ë°ì´í„° ìˆ˜

```py
customer_clustering.columns = ["ì›”í‰ê· ê°’", "ì›”ì¤‘ì•™ê°’", "ì›”ìµœëŒ“ê°’", "ì›”ìµœì†Ÿê°’", "íšŒì›ê¸°ê°„", "cluster"]
customer_clustering.groupby("cluster").count()
```
![alt text](/assets/img_20240924/image-5.png)

### ê·¸ë£¹ë³„ í‰ê· 

```py
customer_clustering.groupby("cluster").mean()
```
![alt text](/assets/img_20240924/image-6.png)

# 034.í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ë¥¼ ê°€ì‹œí™”í•˜ì

### ì°¨ì› ì¶•ì†Œë¥¼ ì´ìš©í•œ ê°€ì‹œí™”

- ì°¨ì› ì¶•ì†Œ: ì •ë³´ë¥¼ ë˜ë„ë¡ ìƒì§€ ì•Šê²Œ í•˜ë©´ì„œ ìƒˆë¡œìš´ ì¶•ì„ ë§Œë“œëŠ” ê²ƒ.

```py
from sklearn.decomposition import PCA
X = customer_clustering_sc
pca = PCA(n_components=2)
pca.fit(X)
x_pca = pca.transform(X)
pca_df = pd.DataFrame(x_pca)
pca_df["cluster"] = customer_clustering["cluster"]

import matplotlib.pyplot as plt
%matplotlib inline
for i in customer_clustering["cluster"].unique():
    tmp = pca_df.loc[pca_df["cluster"]==i]
    plt.scatter(tmp[0], tmp[1])
```
![alt text](/assets/img_20240924/image-9.png)

# â•2ê°œì˜ ì¶•ì´ ì–´ë–¤ ë³€ìˆ˜ë¡œ êµ¬ì„±ë˜ì–´ìˆì„ê¹Œ?

â—chaptGPTì—ê²Œ ë„ì›€ì„ ë°›ìŒ.

### ë¡œë”©ìŠ¤ êµ¬í•˜ê¸°

PCA ëª¨ë¸ì„ fití•œ í›„, ë¡œë”©ìŠ¤ëŠ” components_ ì†ì„±ì— ì €ì¥ë©ë‹ˆë‹¤. ì´ ê°’ì€ ì£¼ì„±ë¶„ë§ˆë‹¤ ì›ë˜ ë°ì´í„°ì…‹ì˜ ê° ë³€ìˆ˜ì— ëŒ€í•œ ê¸°ì—¬ë„ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì¦‰, ë¡œë”©ìŠ¤ í–‰ë ¬ì—ì„œ ê° í–‰ì€ í•˜ë‚˜ì˜ ì£¼ì„±ë¶„ì„ ë‚˜íƒ€ë‚´ê³ , ê° ì—´ì€ ì›ë˜ ë°ì´í„°ì˜ í”¼ì²˜(ë³€ìˆ˜)ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.

```py
import pandas as pd

# PCAì— ì‚¬ìš©ëœ ë³€ìˆ˜ë“¤ë§Œ ì„ íƒí•´ì„œ ë¡œë”©ìŠ¤ ìƒì„±
used_columns = customer_clustering.columns[:5]  # PCAì— ì‚¬ìš©ëœ 5ê°œì˜ ì—´ì„ ì„ íƒ
loadings = pd.DataFrame(pca.components_, columns=used_columns)
print(loadings)
```
![alt text](/assets/img_20240924/image-8.png)

- í¬ê¸° (ì ˆëŒ€ê°’): ì£¼ì„±ë¶„ì—ì„œ ì¤‘ìš”í•œ ì—­í• ì„ í•˜ëŠ” ë³€ìˆ˜ëŠ” ê°’ì˜ **í¬ê¸°(ì ˆëŒ€ê°’)**ì— ë”°ë¼ ê²°ì •ë©ë‹ˆë‹¤. ì–‘ìˆ˜ë“  ìŒìˆ˜ë“  ê°’ì´ í¬ë©´, ê·¸ ë³€ìˆ˜ê°€ ì£¼ì„±ë¶„ì— í° ì˜í–¥ì„ ë¯¸ì¹œë‹¤ê³  í•´ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.<br><br>
- ë°©í–¥: ì–‘ìˆ˜ë‚˜ ìŒìˆ˜ëŠ” ë‹¨ìˆœíˆ ë³€ìˆ˜ì™€ ì£¼ì„±ë¶„ ê°„ì˜ ë°©í–¥ì„±ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ë‘ ë³€ìˆ˜ ëª¨ë‘ ì²« ë²ˆì§¸ ì£¼ì„±ë¶„ì—ì„œ ì ˆëŒ€ê°’ì´ í¬ì§€ë§Œ, í•œ ë³€ìˆ˜ëŠ” ì–‘ìˆ˜, ë‹¤ë¥¸ ë³€ìˆ˜ëŠ” ìŒìˆ˜ë¼ë©´ ì´ ë‘ ë³€ìˆ˜ëŠ” ì„œë¡œ ìƒë°˜ëœ ë°©í–¥ìœ¼ë¡œ ì£¼ì„±ë¶„ì— ê¸°ì—¬í•˜ê³  ìˆë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤.

# 035.í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ íƒˆí‡´ íšŒì›ì˜ ê²½í–¥ì„ íŒŒì•…í•˜ì


### ê·¸ë£¹ë³„ íƒˆí‡´/ì§€ì† íšŒì› ì§‘ê³„

íƒˆí‡´ íšŒì›ì„ íŠ¹ì •í•˜ê¸° ìœ„í•´ì„œ is_deleted ì—´ì„ customer_clusteringì— ì¶”ê°€í•´ì„œ cluster ë° is_deletedë³„ë¡œ ì§‘ê³„í•´ ë³´ê² ìŠµë‹ˆë‹¤.

```py
customer_clustering = pd.concat([customer_clustering, customer], axis=1)
# indexë¡œ ì—°ê²°ë˜ì–´ ìˆê¸° ë•Œë¬¸ì— ê²°í•©ê°€ëŠ¥
customer_clustering.groupby(["cluster", "is_deleted"], 
as_index=False).count()[["cluster", "is_deleted", "customer_id"]]
# is deleted: 0(stay),1(íƒˆí‡´)
```
![alt text](/assets/img_20240924/image-10.png)

### ê·¸ë£¹/ì •ê¸°ì  ì´ìš© í”Œë˜ê·¸ë³„ ì§‘ê³„

```py
customer_clustering.groupby(["cluster", "routine_flg"],as_index=False).count()[["cluster", "routine_flg", "customer_id"]]
```
![alt text](/assets/img_20240924/image-11.png)

# 036.ë‹¤ìŒ ë‹¬ì˜ ì´ìš© íšŸìˆ˜ ì˜ˆì¸¡ì„ ìœ„í•´ ë°ì´í„°ë¥¼ ì¤€ë¹„í•˜ì

ê³¼ê±° 6ê°œì›”ì˜ ì´ìš© ë°ì´í„°ë¥¼ ì‚¬ìš©í•´ ë‹¤ìŒ ë‹¬ì˜ ì´ìš© íšŸìˆ˜ë¥¼ ì˜ˆì¸¡í•´ë³´ì(íšŒê·€ë¶„ì„)

### ë°ì´í„° ìˆ˜ì •

íŠ¹ì • ê³ ê°ì˜ íŠ¹ì • ì›”ë³„ ë°ì´í„° í•„ìš”!(6ê°œì›” ë°ì´í„°ì™€ ê·¸ ë‹¤ìŒë‹¬ ë°ì´í„°ì¸ ì •ë‹µ ë°ì´í„° í•„ìš”)

```py
uselog["usedate"] = pd.to_datetime(uselog["usedate"])
uselog["ì—°ì›”"] = uselog["usedate"].dt.strftime("%Y%m")
uselog_months = uselog.groupby(["ì—°ì›”", "customer_id"],as_index=False).count()
uselog_months.rename(columns={"log_id":"count"}, inplace=True)
del uselog_months["usedate"]
uselog_months.head()
```
![alt text](/assets/img_20240924/image-12.png)

ê·¸ë¦¬ê³  ì´ë²ˆ ë‹¬ë¶€í„° ê³¼ê±° 5ê°œì›”ë¶„ì˜ ì´ìš© íšŸìˆ˜ì™€ ë‹¤ìŒ ë‹¬ì˜ ì´ìš© íšŸìˆ˜ë¥¼ ì €ì¥(2018.10~2019.3)

```py
year_months = list(uselog_months["ì—°ì›”"].unique())
predict_data = pd.DataFrame()
for i in range(6, len(year_months)):
    # 201810~201903
    tmp = uselog_months.loc[uselog_months["ì—°ì›”"]==year_months[i]]
    tmp.rename(columns={"count":"count_pred"}, inplace=True)
    
    for j in range(1,7):
        tmp_before = uselog_months.loc[uselog_months["ì—°ì›”"]==year_months[i-j]]
        # 6ê°œì›” ì „ê¹Œì§€
        del tmp_before["ì—°ì›”"]
        tmp_before.rename(columns={"count":"count_{}".format(j-1)}, inplace=True)
        tmp = pd.merge(tmp, tmp_before, on="customer_id", how="left")
    predict_data=pd.concat([predict_data, tmp], ignore_index=True)
predict_data.head()
```
![alt text](/assets/img_20240924/image-13.png)

â—NANê°’ì€ ê°€ì… ê¸°ê°„ì´ ì§§ì•„ì„œ ë°ì´í„°ê°€ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê²½ìš°

```py
predict_data = predict_data.dropna()
predict_data = predict_data.reset_index(drop=True)
#ì¬ì •ë ¬
predict_data.head()
```
![alt text](/assets/img_20240924/image-14.png)

# 037.íŠ¹ì§•ì´ ë˜ëŠ” ë³€ìˆ˜ë¥¼ ì¶”ê°€í•˜ì

ê¸°ë³¸ ë°ì´í„°ê°€ ì‹œê³„ì—´ ë°ì´í„°ì´ë¯€ë¡œ íšŒì› ê¸°ê°„ì„ ì¶”ê°€í•´ë³´ì

### ê³ ê° ë°ì´í„°ì— start_date ì¹¼ëŸ¼ ê²°í•©

```py
predict_data = pd.merge(predict_data, customer[["customer_id", "start_date"]], on="customer_id", how="left")
predict_data.head()
```
![alt text](/assets/img_20240924/image-15.png)

### íšŒì› ê¸°ê°„ ì¶”ê°€

ì—°ì›”ê³¼ start_dateì˜ ì°¨ì´ë¥¼ ì´ìš©í•´ íšŒì› ê¸°ê°„ì„ ì›” ë‹¨ìœ„ë¡œ ì‘ì„±í•´ ë³´ì.

```py
predict_data["now_date"] = pd.to_datetime(predict_data["ì—°ì›”"], format="%Y%m")
predict_data["start_date"] = pd.to_datetime(predict_data["start_date"])
from dateutil.relativedelta import relativedelta
predict_data["period"] = None
for i in range(len(predict_data)):
    delta = relativedelta(predict_data["now_date"][i], predict_data["start_date"][i])
    predict_data["period"][i] = delta.years*12 + delta.months
predict_data.head()
```
![alt text](/assets/img_20240924/image-16.png)

# 038.ë‹¤ìŒ ë‹¬ ì´ìš© íšŸìˆ˜ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì„ êµ¬ì¶•í•˜ì

### ì˜ˆì¸¡ ëª¨ë¸ êµ¬ì¶•

```py
predict_data = predict_data.loc[predict_data["start_date"]>=pd.to_datetime("20180401")]
# ì˜¤ë˜ëœ íšŒì›ì€ ê°€ì… ì‹œê¸° ë°ì´í„°ê°€ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ ì´ìš© íšŸìˆ˜ê°€ ì•ˆì •ì ì¼ ê°€ëŠ¥ì„±ì´ ìˆê¸° ë•Œë¬¸ì— ì˜¤ë˜ëœ íšŒì›ì€ ë¹¼ê³  ëª¨ë¸ êµ¬ì¶•
from sklearn import linear_model
import sklearn.model_selection
model = linear_model.LinearRegression()
X = predict_data[["count_0", "count_1", "count_2", "count_3", "count_4", "count_5", "period"]]
y = predict_data["count_pred"]
X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X,y)
# í•™ìŠµìš© ë°ì´í„° 75%, í‰ê°€ìš© ë°ì´í„° 25%
model.fit(X_train, y_train)
```
![alt text](/assets/img_20240924/image-17.png)

### íšŒê·€ ëª¨ë¸ì˜ ì •í™•ë„

```py
print(model.score(X_train, y_train))
# 0.6070880656984303
print(model.score(X_test, y_test))
# 0.6101178418242166
```

# 039.ëª¨ë¸ì— ê¸°ì—¬í•˜ëŠ” ë³€ìˆ˜ë¥¼ í™•ì¸í•˜ì

### ê¸°ì—¬í•˜ëŠ” ë³€ìˆ˜

```py
coef = pd.DataFrame({"feature_names":X.columns, "coefficient":model.coef_})
coef
```
![alt text](/assets/img_20240924/image-18.png)

# 040.ë‹¤ìŒ ë‹¬ì˜ ì´ìš© íšŸìˆ˜ë¥¼ ì˜ˆì¸¡í•˜ì

### ì˜ˆì¸¡

íšŒì› ë‘ ëª…ì˜ ì´ìš© ë°ì´í„°ë¥¼ ì‘ì„±í•´ ë³´ì.
```py
x1 = [3,4,4,6,8,7,8]
x2 = [2,2,3,3,4,6,8]
x_pred = [x1, x2]

model.predict(x_pred)
# array([3.81182518, 1.97102059])

# ì¶œë ¥
uselog_months.to_csv("use_log_months.csv", index=False)
```
